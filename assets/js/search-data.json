{
  
    
        "post0": {
            "title": "AI로 기사의 정치 성향 탐지하기(feat. 확증편향)",
            "content": "POP THE FILTER BUBBLE . 이 글은 상시적으로 업데이트 될 수 있음을 알려드립니다. | 잘못된 내용, 질문, 제안할 아이디어 등은 자유롭게 댓글로 알려주시길 바라니다. | 대학 시절 Eli Praiser가 쓴 &lt;The Filter Bubble - How The New Personalized Web Is Changing What We Read And How We Think&gt;라는 책을 읽었다. 머리를 한 대 세게 얻어맞은 기분이었다. 그 후 이 주제는 오랫동안 내 관심사 분야에 올라 있었다. . 필터버블. 물론 논란이 많은 개념이다. 필터버블 현상이 대의 민주주주의를 위협하고 있다는 시선도, 실체 없는 기우라는 시선도 있다. 개인적으로 나는 &#39;내가 진짜 필터버블에 갇혀 있나?&#39;라는 생각이 들 때가 몇 번 있었다. 가령, 나와 내 친구들 사이에서는 너무 당연한 것이 나의 준거집단에서 한 발자국만 벗어나면 튀는 목소리가 된다는 것을 어렴풋이 느꼈을 때가 그렇다. 이런 생각이 들 때마다 의도적으로 필터버블 걷어내기 작업을 한다. 페이스북에서 전혀 동의하지 않는 게시물에 &#39;좋아요&#39;를 누른다든지 따위 작업 말이다. 물론 페이스북 알고리듬을 들여다볼 수 없는 까닭에, 이 작업이 실제로 효과가 있는지 알 길은 없다. . &#44033;&#49444;&#54616;&#44256;, &#50836;&#45716; &#45236;&#44032; &#54596;&#53552;&#48260;&#48660;&#50640; &#44288;&#49900;&#51060; &#51080;&#45796;&#45716; &#44163;! . 필터버블을 감시하고, 이 버블을 터뜨리기 위한 가장 확실한 방법은 플랫폼 차원에서 접근하는 것이다. 실제로 이라는 미국의 데이터 기반 탐사보도 비영리 뉴스룸은 시민 브라우저(Citizen Browser) 프로젝트&lt;/a&gt;에서 SNS 플랫폼(페이스북) 차원에서 분석하고 가시화한다.&lt;/p&gt; 이 프로젝트를 눈여겨 보며, 그리고 감탄하며 나도 필터버블을 완화하기 위한 기술적 시도에 나서고 싶었다. The Markup처럼 플랫폼 차원의 접근은 현재 단계에서 불가하다는 판단에서, 지금 할 수 있는 수준에서 필터버블을 터뜨리는 방법을 고민해보았다. . &#51068;&#47749;, POP THE FILTER BUBBLE . POP THE FILTER BUBBLE은 자연어처리(NLP)와 데이터 기반 콘텐츠 추천 시스템을 결합해 필터버블 완화 효과가 있을 것으로 기대하는 뉴스 추천 시스템을 제안한다. . 그 방법을 요약하자면, . (1) 목적 : 뉴스 콘텐츠에서의 필터버블 현상 완화 . (2) 방법론 : 독자가 읽고 있는 뉴스와 다루는 소재는 같고 정치 성향은 다른 뉴스 콘텐츠를 추천 . (3) 기술적 방법론 : 두 가지 모델을 결합한다. 기사 텍스트의 정치 성향 탐지 모델(feat. BERT) + 독자의 뉴스 이용 로그 및 기사 제목 텍스트를 이용한 추천 시스템 모델(feat. Deep Knowledge-Aware Network for News Recommendation) . 모델의 성능 평가, 한계, POP THE FILTER BUBBLE Phase2에서 하고 싶은 것 등, 구체적인 내용은 아래 글에서 확인하길 바란다. . 덧, 아래 글은 서수민 님과 함께 썼다는 것을 알려드립니다. . . POP THE FILTER BUBBLE . 연구 배경 및 목적 1.1 확증 편향을 일으키는 필터버블 | 1.2 필터버블을 터뜨리는 뉴스 추천 시스템 제안 | . | BERT 파인튜닝을 이용한 텍스트의 정치 성향 탐지 모델 | 2.1 훈련데이터 - IBC | 2.2 BERT 파인 튜닝 | 2.3 텍스트 정치 성향 탐지 모델 개발 과정 | 2.4 모델 성능 평가 IBC 데이터를 이용한 평가 | 별도 뉴스 데이터를 이용한 평가 | . | . 필터버블을 터뜨리는 뉴스 추천 시스템 | 3.1 훈련 데이터 - MIND | 3.2 추천 알고리즘 - DKN 알고리즘 선정 이유 | 알고리즘 설명 | 추천 시스템 학습 과정 | . | 3.3 필터버블을 터뜨리기 위한 추천 시스템 개발 과정 및 결과 | . 남는 질문들과 앞으로의 계획 | 참고 문헌 | . 1. &#50672;&#44396; &#48176;&#44221; &#48143; &#47785;&#51201; . 1.1 &#54869;&#51613;&#54200;&#54693;&#51012; &#51068;&#51004;&#53412;&#45716; &#54596;&#53552;&#48260;&#48660; . 우리는 흔히 IT 기술의 발전 덕분에 그 어느 때보다 다양한 정보에 쉽게 접근할 수 있다고 믿는다. 인터넷에 접속해 지구 정반대 편에서 일어나는 일도 빠르고 손쉽게 알 수 있고, 다양한 의견을 접할 수 있다는 기대다. 하지만 현실은 이 믿음과 판이하다. 우리가 접하는 정보를 ‘필터링&#39; 하는 필터버블이 존재하기 때문이다. . 필터버블은 온라인 사용자별로 필터링 된 정보가 마치 거품(버블)처럼 사용자를 가둬버리는 정보 필터링 현상이다. 2009년 12월 구글이 미국 내 사용자의 검색결과 개인 맞춤화를 도입한 후, 개인 맞춤화 정보 제공은 온라인 서비스의 성공 척도가 됐다고 해도 과언이 아니다. . . 출처 : [spreadprivacy](https://spreadprivacy.com/)온라인 서비스를 제공하는 기업들은 개인 맞춤화 알고리즘으로 사용자가 온라인에 남긴 데이터, 인구통계학적 특성을 기반으로 동질의 정보를 사용자에게 많이 노출하는 방식으로 사용자가 접하는 정보를 설계한다. 검색 서비스를 예로 들면, 똑같은 단어를 검색하더라도 누가 검색하느냐에 따라 서로 다른 결과가 나오는 것이다. . 이같은 개인 맞춤화 알고리즘은 사람들이 다양한 정보를 접하는 것을 막고 유사한 정보를 소비하게끔 유도한다. 이로써 ‘인터넷을 통해 다양한 정보와 의견을 접할 수 있다&#39;는 믿음과 정반대로 사람들은 점점 동질의 정보를 소비한다. 그리고 이같은 ‘정보 노출의 설계&#39;는 ‘의사결정의 설계&#39;로까지 이어진다. 사용자가 다양한 정보를 접할 기회를 가로막아 확증편향의 함정에 쉽게 빠지게 만드는 것이다. . 필터버블과 이로 인한 확증편향은 특히 필터버블이 뉴스 콘텐츠를 필터링할 때 심각한 사회 문제로 작용한다. 정치·사회·이념의 양극화를 일으키는 요인으로 작용하고, 이는 대의민주주의를 위협으로까지 이어질 수 있다. 필터버블을 처음 주장한 엘리 프레이저는 필터버블이 비민주적인 사회를 불러올 수 있다는 점을 경고했다. . 1.2 &#54596;&#53552;&#48260;&#48660;&#51012; &#53552;&#46888;&#47532;&#45716; &#45684;&#49828; &#52628;&#52380; &#49884;&#49828;&#53596; &#51228;&#50504; . 뉴스 콘텐츠에서의 필터버블 현상을 막기 위해 본 프로젝트에서는 ▲텍스트의 정치 성향 탐지 모델 ▲사용자의 뉴스 이용 로그 및 제목 텍스트를 이용한 추천 시스템 모델을 결합해 새로운 뉴스 추천 서비스를 제안하려 한다. . 2. BERT &#54028;&#51064;&#53916;&#45789;&#51012; &#51060;&#50857;&#54620; &#53581;&#49828;&#53944; &#51221;&#52824; &#49457;&#54693; &#53456;&#51648; &#47784;&#45944; . 본 프로젝트팀은 텍스트를 입력하면 해당 텍스트의 정치 성향을 탐지하는 모델을 개발했다. 정치 성향이 진보일 때는 0, 보수일 때는 1을 출력한다. . 2.1 &#54984;&#47144; &#45936;&#51060;&#53552; . 텍스트의 정치 성향을 탐지하기 위해 the Ideological Books Corpus(IBC) 데이터의 일부를 사용했다. IBC는 2013년 Gross가 만든 데이터로, 정치적 편향이 뚜렷하다고 알려진 미국 인사들의 저작물을 모은 데이터다. 정치학자들이 메뉴얼화된 기준에 따라 저자의 정치 성향을 판단해, 저자의 저작물에 이 정치 성향을 라벨링 한 형태다. 저작물(document) 단위로 이뤄져 있고 각 저작물에는 저자의 정치적 성향에 따라 ‘진보(lib)&#39;, ‘중도(neutral)&#39;, ‘보수(con)&#39; 중 하나의 라벨링이 달려있다. . 본 프로젝트에서는 전체 IBC 데이터를 사용하지 않고 2014년 Mohit Iyyer 등이 IBC 데이터를 한 차례 더 가공해 만든 IBC 일부 데이터를 사용했다. Mohit Iyyer 연구팀은 Political Ideology Detection Using Recursive Neural Networks 연구에서 저작물(document) 단위를 문장 단위로 쪼개고 정치적 편향이 뚜렷하지 않은 문장을 제외했다. 그리고 크라우드소싱 플랫폼을 이용해 문장 단위 정치 성향 라벨링 작업을 했다. 이렇게 만들어진 재가공 IBC 데이터세트는 진보 성향 문장 2025개, 중도 성향 문장 600개, 보수 성향 문장 1701로 구성돼 있다. 본 프로젝트에서는 중도 문장 600개를 제외한 진보 및 보수 문장만을 사용했다. . . 2.2 BERT &#54028;&#51064; &#53916;&#45789; . 텍스트 정치 성향 탐지기를 개발하기 위해 파이토치 프레임워크가 제공하는 BERT 파인튜닝 모델을 이용했다. . BERT(Bidirectional Encoder Representations from Transformers)는 구글이 만든 언어 모델로, 자연어처리(NLP) 분야에서의 전이학습(transfer learning)을 위해 고안됐다. BooksCorpus 800만 단어와 영어 위키백과 2500만 단어를 사전 훈련해 생성한 사전 학습 모델(pre-trained BERT model)을 제공하고, Transformer의 encoder 부분만 사용한다. BERT를 사용하면 사전 훈련된 고성능 언어 모델을 전이학습 시켜 다른 자연어처리에 적용할 수 있다. 또 Transformer는 모든 토큰을 순서대로 입력받는 RNN과 달리 모든 토큰을 한 번에 받아 처리하기 때문에 학습이 빠르다는 점 등 장점이 있다. . . 출처 : [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)BERT 파인튜닝(Fine-Tuning)은 사전 학습된 BERT 모델 아키텍처 위에 레이어를 하나 추가해 모델을 훈련함으로써, 개별 태스크를 더 잘 수행하도록 한다. . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; https://medium.com/@aniruddha.choudhury94/part-2-bert-fine-tuning-tutorial-with-pytorch-for-text-classification-on-the-corpus-of-linguistic-18057ce330e1 . https://web.stanford.edu/class/cs224n/reports/custom/report43.pdf . https://www.allsides.com/media-bias/media-bias-ratings . import tensorflow as tf # Get the GPU device name. device_name = tf.test.gpu_device_name() # The device name should look like the following: if device_name == &#39;/device:GPU:0&#39;: print(&#39;Found GPU at: {}&#39;.format(device_name)) else: raise SystemError(&#39;GPU device not found&#39;) . Found GPU at: /device:GPU:0 . Hugging Face에 있는 transformers 패키지를 설치한다. Hugging Face는 BERT를 사용하기 위한 파이토치 인터페이스를 사용할 수 있게 한다. . !pip install transformers . Collecting transformers Downloading https://files.pythonhosted.org/packages/81/89/f07e7a884072ad37b1b6b1578637ab36152e0251d74abb950d967a59904e/transformers-4.3.1-py3-none-any.whl (1.8MB) |████████████████████████████████| 1.8MB 8.1MB/s Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5) Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9) Requirement already satisfied: dataclasses; python_version &lt; &#34;3.7&#34; in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8) Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0) Collecting sacremoses Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB) |████████████████████████████████| 890kB 35.7MB/s Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20) Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12) Collecting tokenizers&lt;0.11,&gt;=0.10.1 Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB) |████████████████████████████████| 3.2MB 50.4MB/s Requirement already satisfied: importlib-metadata; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0) Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1) Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging-&gt;transformers) (2.4.7) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (2020.12.5) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests-&gt;transformers) (1.24.3) Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (1.15.0) Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (7.1.2) Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses-&gt;transformers) (1.0.0) Requirement already satisfied: typing-extensions&gt;=3.6.4; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;transformers) (3.7.4.3) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version &lt; &#34;3.8&#34;-&gt;transformers) (3.4.0) Building wheels for collected packages: sacremoses Building wheel for sacremoses (setup.py) ... done Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3aa67db83a382f762ad0378543630bf82a3a600163fea86b18de5c255a4652f5 Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45 Successfully built sacremoses Installing collected packages: sacremoses, tokenizers, transformers Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.1 . import re import sys import random import pandas as pd import torch import numpy as np import torch.nn as nn import torch.nn.functional as F from torch.autograd import Variable from torchtext import data, datasets from transformers import BertTokenizer, BertModel import tensorflow as tf . sentence, label 2개 칼럼을 가진 IBC dataset을 업로드한다. . train_df = pd.read_csv(&#39;/content/drive/Shareddrives/DeepTextLab/train_data.csv&#39;) test_df = pd.read_csv(&#39;/content/drive/Shareddrives/DeepTextLab/test_data.csv&#39;) . train_df.label.unique() . array([10, 0, 5]) . train_df = train_df.loc[train_df.label != 5] test_df = test_df.loc[test_df.label != 5] . train_df.loc[train_df[&#39;label&#39;] == 10, &#39;label&#39;] = 1 test_df.loc[test_df[&#39;label&#39;] == 10, &#39;label&#39;] = 1 . print(&#39;트레인 데이터 크기 :&#39;, len(train_df)) print(&#39;테스트 데이터 크기 :&#39;, len(test_df)) . 트레인 데이터 크기 : 2983 테스트 데이터 크기 : 743 . print(test_df.dtypes) . text object label int64 dtype: object . train_df.head(3) . text label . 0 During the 1920s , Great Britain , terrified o... | 1 | . 1 Those who would save the Amazon from disastrou... | 0 | . 2 However , the report noted that , `` Deaths we... | 0 | . train_df.rename(columns={&#39;text&#39;:&#39;sentence&#39;}, inplace=True) test_df.rename(columns={&#39;text&#39;:&#39;sentence&#39;}, inplace=True) . train_df.head(3) . sentence label . 0 During the 1920s , Great Britain , terrified o... | 1 | . 1 Those who would save the Amazon from disastrou... | 0 | . 2 However , the report noted that , `` Deaths we... | 0 | . sentences = train_df.sentence.values labels = train_df.label.values . sentences . array([&#39;During the 1920s , Great Britain , terrified of having to face depreciation of the pound as a result of running the printing presses , pressured the United States and other powers to inflate in concert with the Bank of England , leading to another global inflationary cycle and economic bubble that burst in 1929 with the great stock market crash .&#39;, &#39;Those who would save the Amazon from disastrous helter-skelter deforestation are also working out the details of schemes to certify soy , cattle , and other Amazonian products as having been sustainably produced ; already there is in place in Brazil a two-year moratorium on forest destruction to plant soy .&#39;, &#39;However , the report noted that , `` Deaths were not classified as being due to coalition forces if households had any uncertainty about the responsible party ; consequently , the number of deaths and the proportion of violent deaths attributable to coalition forces could be conservative estimates .&#39;, ..., &#39;The key to successfully using nullification is to expose the federal government as the aggressive , unconstitutional usurper , and states would be wise to not directly confront them .&#39;, &#39;Finally , there is the chronic flaw in all those pie chart-type analyses purporting to show how terrible the distribution of wealth is in the United States -- the failure to relate age to wealth , income , and productivity .&#39;, &#39;A free people must never accept this principle , which can only lead to domination by the artificial entity of the corporation , which is driven by the singular yardstick of profit .&#39;], dtype=object) . labels . array([1, 0, 0, ..., 1, 1, 0]) . BERT &#53664;&#53356;&#45208;&#51060;&#51200;&#47196; &#53664;&#53356;&#45208;&#51060;&#51669; . from transformers import BertTokenizer # Load the BERT tokenizer. print(&#39;Loading BERT tokenizer...&#39;) tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;, do_lower_case=True) . Loading BERT tokenizer... . input_ids = [] # For every sentence... for sent in sentences: # `encode` will: # (1) Tokenize the sentence. # (2) Prepend the `[CLS]` token to the start. # (3) Append the `[SEP]` token to the end. # (4) Map tokens to their IDs. encoded_sent = tokenizer.encode( sent, # Sentence to encode. add_special_tokens = True, # Add &#39;[CLS]&#39; and &#39;[SEP]&#39; # This function also supports truncation and conversion # to pytorch tensors, but we need to do padding, so we # can&#39;t use these features :( . # max_length = 128, # Truncate all sentences. # return_tensors = &#39;pt&#39;, # Return pytorch tensors. ) # Add the encoded sentence to the list. input_ids.append(encoded_sent) # Print sentence 0, now as a list of IDs. print(&#39;Original: &#39;, sentences[1]) print(&#39;Token IDs:&#39;, input_ids[1]) # Token ID 100 = [UNK] # Token ID 101 = [CLS] # Token ID 102 = [SEP] # Token ID 0 = [PAD] . Original: Those who would save the Amazon from disastrous helter-skelter deforestation are also working out the details of schemes to certify soy , cattle , and other Amazonian products as having been sustainably produced ; already there is in place in Brazil a two-year moratorium on forest destruction to plant soy . Token IDs: [101, 2216, 2040, 2052, 3828, 1996, 9733, 2013, 16775, 2002, 21928, 1011, 15315, 20042, 2121, 13366, 25794, 2024, 2036, 2551, 2041, 1996, 4751, 1997, 11683, 2000, 8292, 28228, 12031, 25176, 1010, 7125, 1010, 1998, 2060, 9733, 2937, 3688, 2004, 2383, 2042, 15770, 8231, 2550, 1025, 2525, 2045, 2003, 1999, 2173, 1999, 4380, 1037, 2048, 1011, 2095, 26821, 24390, 2006, 3224, 6215, 2000, 3269, 25176, 1012, 102] . Padding &amp; Truncating . print(&#39;Max sentence length: &#39;, max([len(sen) for sen in input_ids])) . Max sentence length: 107 . 가장 긴 문장이 토큰 107개짜리 문장이므로, 이 값보다 살짝 큰 110를 MAX_LEN로 지정 . import keras . from keras.preprocessing.sequence import pad_sequences # Set the maximum sequence length. # I&#39;ve chosen 120 somewhat arbitrarily. It&#39;s slightly larger than the # maximum training sentence length of 107... MAX_LEN = 110 print(&#39; nPadding/truncating all sentences to %d values...&#39; % MAX_LEN) print(&#39; nPadding token: &quot;{:}&quot;, ID: {:}&#39;.format(tokenizer.pad_token, tokenizer.pad_token_id)) # Pad our input tokens with value 0. # &quot;post&quot; indicates that we want to pad and truncate at the end of the sequence, # as opposed to the beginning. input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=&quot;long&quot;, value=0, truncating=&quot;post&quot;, padding=&quot;post&quot;) # ==&gt; 패딩은 토큰 아이디 0으로 함. print(&#39; Done.&#39;) . Padding/truncating all sentences to 110 values... Padding token: &#34;[PAD]&#34;, ID: 0 Done. . Attention Masks . attention_masks = [] # For each sentence... for sent in input_ids: # Create the attention mask. # - If a token ID is 0, then it&#39;s padding, set the mask to 0. ==&gt; 토큰 아이디가 0이면 어텐션 마스크에도 0을 # - If a token ID is &gt; 0, then it&#39;s a real token, set the mask to 1. ==&gt; 토큰 아이디가 0이 아니라면, 어텐션 마스크에는 1을 att_mask = [int(token_id &gt; 0) for token_id in sent] # Store the attention mask for this sentence. attention_masks.append(att_mask) . Training &amp; Validation Split . # training from sklearn.model_selection import train_test_split # Use 90% for training and 10% for validation. train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2021, test_size=0.1) # Do the same for the masks. train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2021, test_size=0.1) . Converting to Pytorch Data Types . # for our model. train_inputs = torch.tensor(train_inputs) validation_inputs = torch.tensor(validation_inputs) train_labels = torch.tensor(train_labels) validation_labels = torch.tensor(validation_labels) train_masks = torch.tensor(train_masks) validation_masks = torch.tensor(validation_masks) . print(len(train_inputs)) print(len(validation_inputs)) . 2684 299 . Create an iterator for our dataset using the torch DataLoader clas . from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler # 파이토치는 data.Dataset으로 사용자 지정 데이터셋을 만들고, data.DataLoader로 데이터를 불러온다. # ==&gt; DataLoader는 데이터를 묶고, 섞고, 병렬처리 과정에서 multiprocessing을 사용할 떄 데이터를 불러오는 모든 기능을 제공하는 반복자(iterator). # DataLoader는 기본적으로 3개 파라미터를 필요로 한다. # 1. 불러올 대상이 되는 데이터 (아래의 경우 train_data) # 2. batch_size # 3. batch_sampler # 이들을 하나씩 지정해주자. # 1. ==&gt; 문장을 토큰화해, 토큰 아이디로 바꾼 train_inputs과 어텐션 마스크인 train_maks, train_labels를 묶어서 train_data만듦. train_data = TensorDataset(train_inputs, train_masks, train_labels) # 2. == &gt; The DataLoader needs to know our batch size for training, so we specify it here. # For fine-tuning BERT on a specific task, the authors recommend a batch size of # 16 or 32. batch_size = 16 # 3.==&gt; sampler는 index를 컨트롤하는 방법이다. randomsampler는 인덱스의 랜덤, replacement 여부, 개수를 선택하게 한다. train_sampler = RandomSampler(train_data) # 이제 1~3 파라미터를 넣어서 train_dataloader를 만든다. train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) # Create the DataLoader for our validation set. 검증 데이터셋에 대해서도 같은 작업 수행 validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels) validation_sampler = SequentialSampler(validation_data) validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size) . train_data[0] . (tensor([ 101, 13587, 3514, 7597, 2031, 2815, 2012, 2030, 2682, 2023, 2504, 2144, 2432, 1010, 2437, 5211, 1999, 14931, 2140, 6786, 8702, 1998, 12996, 4892, 5211, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor(1)) . &#51064;&#54411; &#45936;&#51060;&#53552;&#44032; &#51456;&#48708;&#46096;&#45796;!! &#51060;&#51228; BERT model&#51012; &#54028;&#51064;&#53916;&#45789; &#54644;&#48372;&#51088;! . BERT Classification &#47784;&#45944; &#48520;&#47084;&#50724;&#44592; . from transformers import BertForSequenceClassification, AdamW, BertConfig # Load BertForSequenceClassification, the pretrained BERT model with a single # linear classification layer on top. ###################### model ####################### model = BertForSequenceClassification.from_pretrained( &quot;bert-base-uncased&quot;, # Use the 12-layer BERT model, with an uncased vocab. num_labels = 2, # The number of output labels--2 for binary classification. # You can increase this for multi-class tasks. output_attentions = False, # Whether the model returns attentions weights. output_hidden_states = False, # Whether the model returns all hidden-states. ) # Tell pytorch to run this model on the GPU. model.cuda() . . Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;] - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . BertForSequenceClassification( (bert): BertModel( (embeddings): BertEmbeddings( (word_embeddings): Embedding(30522, 768, padding_idx=0) (position_embeddings): Embedding(512, 768) (token_type_embeddings): Embedding(2, 768) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) (encoder): BertEncoder( (layer): ModuleList( (0): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (1): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (2): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (3): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (4): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (5): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (6): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (7): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (8): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (9): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (10): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (11): BertLayer( (attention): BertAttention( (self): BertSelfAttention( (query): Linear(in_features=768, out_features=768, bias=True) (key): Linear(in_features=768, out_features=768, bias=True) (value): Linear(in_features=768, out_features=768, bias=True) (dropout): Dropout(p=0.1, inplace=False) ) (output): BertSelfOutput( (dense): Linear(in_features=768, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) (intermediate): BertIntermediate( (dense): Linear(in_features=768, out_features=3072, bias=True) ) (output): BertOutput( (dense): Linear(in_features=3072, out_features=768, bias=True) (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True) (dropout): Dropout(p=0.1, inplace=False) ) ) ) ) (pooler): BertPooler( (dense): Linear(in_features=768, out_features=768, bias=True) (activation): Tanh() ) ) (dropout): Dropout(p=0.1, inplace=False) (classifier): Linear(in_features=768, out_features=2, bias=True) ) . params = list(model.named_parameters()) print(&#39;The BERT model has {:} different named parameters. n&#39;.format(len(params))) print(&#39;==== Embedding Layer ==== n&#39;) for p in params[0:5]: print(&quot;{:&lt;55} {:&gt;12}&quot;.format(p[0], str(tuple(p[1].size())))) print(&#39; n==== First Transformer ==== n&#39;) for p in params[5:21]: print(&quot;{:&lt;55} {:&gt;12}&quot;.format(p[0], str(tuple(p[1].size())))) print(&#39; n==== Output Layer ==== n&#39;) for p in params[-4:]: print(&quot;{:&lt;55} {:&gt;12}&quot;.format(p[0], str(tuple(p[1].size())))) . The BERT model has 201 different named parameters. ==== Embedding Layer ==== bert.embeddings.word_embeddings.weight (30522, 768) bert.embeddings.position_embeddings.weight (512, 768) bert.embeddings.token_type_embeddings.weight (2, 768) bert.embeddings.LayerNorm.weight (768,) bert.embeddings.LayerNorm.bias (768,) ==== First Transformer ==== bert.encoder.layer.0.attention.self.query.weight (768, 768) bert.encoder.layer.0.attention.self.query.bias (768,) bert.encoder.layer.0.attention.self.key.weight (768, 768) bert.encoder.layer.0.attention.self.key.bias (768,) bert.encoder.layer.0.attention.self.value.weight (768, 768) bert.encoder.layer.0.attention.self.value.bias (768,) bert.encoder.layer.0.attention.output.dense.weight (768, 768) bert.encoder.layer.0.attention.output.dense.bias (768,) bert.encoder.layer.0.attention.output.LayerNorm.weight (768,) bert.encoder.layer.0.attention.output.LayerNorm.bias (768,) bert.encoder.layer.0.intermediate.dense.weight (3072, 768) bert.encoder.layer.0.intermediate.dense.bias (3072,) bert.encoder.layer.0.output.dense.weight (768, 3072) bert.encoder.layer.0.output.dense.bias (768,) bert.encoder.layer.0.output.LayerNorm.weight (768,) bert.encoder.layer.0.output.LayerNorm.bias (768,) ==== Output Layer ==== bert.pooler.dense.weight (768, 768) bert.pooler.dense.bias (768,) classifier.weight (2, 768) classifier.bias (2,) . Optimizer &amp; Learning Rate Scheduler . # I believe the &#39;W&#39; stands for &#39;Weight Decay fix&quot; # ==&gt; AdamW 옵티마이저 정리 글 : https://hiddenbeginner.github.io/deeplearning/paperreview/2019/12/29/paper_review_AdamW.html optimizer = AdamW(model.parameters(), lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5 eps = 1e-8 # args.adam_epsilon - default is 1e-8. ) from transformers import get_linear_schedule_with_warmup # Number of training epochs (authors recommend between 2 and 4) epochs = 4 # Total number of training steps is number of batches * number of epochs. total_steps = len(train_dataloader) * epochs # Create the learning rate scheduler. scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, # Default value in run_glue.py num_training_steps = total_steps) . Training Loop . 트레이닝 루프를 도는 동안 하는 것들 | 인풋 데이터와 라벨을 unpack | GPU에 unpacked 데이터 로드 | 이전 pass에서의 gradients 계산된 것을 초기화. (디폴트는 gradients가 계속 쌓이는 것인데, 원치 않으므로 초기화 설정) | Forward pass ( feed input data through the network) | Backward pass (backpropagation) | 모델의 네트워크에 optimizer.step()을 사용해 파라미터를 업데이트하라고 알려줌 | Track variables for monitoring progress | . 검증 루프를 도는 동안 하는 것들 | 인풋 데이터와 라벨을 unpack | GPU에 unpacked 데이터 로드 | Forward pass ( feed input data through the network) | 검증 데이터에서 loss를 계산하고, track variables for monitoring progress | . import numpy as np # Function to calculate the accuracy of our predictions vs labels def flat_accuracy(preds, labels): pred_flat = np.argmax(preds, axis=1).flatten() # ==&gt; flatten() 다차원 배열을 1차원 배열로 평평하게 펴주는 np 함수 labels_flat = labels.flatten() return np.sum(pred_flat == labels_flat) / len(labels_flat) # ==&gt; 예측한 라벨과 실제 라벨이 일치한 갯수의 총합 / 총 데이터 갯수 . 경과 시간 포맷을 위한 기능 . import time import datetime def format_time(elapsed): &#39;&#39;&#39; Takes a time in seconds and returns a string hh:mm:ss &#39;&#39;&#39; # Round to the nearest second. elapsed_rounded = int(round((elapsed))) # Format as hh:mm:ss return str(datetime.timedelta(seconds=elapsed_rounded)) . &#51060;&#51228; training &#51456;&#48708; &#50756;&#47308;!! . &#39;&#39;&#39; BERT 모델 기본 설정. &#39;&#39;&#39; device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) . import random # This training code is based on the `run_glue.py` script here: # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128 # Set the seed value all over the place to make this reproducible. seed_val = 42 random.seed(seed_val) np.random.seed(seed_val) torch.manual_seed(seed_val) torch.cuda.manual_seed_all(seed_val) # Store the average loss after each epoch so we can plot them. loss_values = [] # For each epoch... for epoch_i in range(0, epochs): # ======================================== # Training # ======================================== # Perform one full pass over the training set. print(&quot;&quot;) print(&#39;======== Epoch {:} / {:} ========&#39;.format(epoch_i + 1, epochs)) print(&#39;Training...&#39;) # Measure how long the training epoch takes. t0 = time.time() # Reset the total loss for this epoch. total_loss = 0 # Put the model into training mode. Don&#39;t be mislead--the call to # `train` just changes the *mode*, it doesn&#39;t *perform* the training. # `dropout` and `batchnorm` layers behave differently during training # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch) model.train() # For each batch of training data... for step, batch in enumerate(train_dataloader): # Progress update every 40 batches. if step % 40 == 0 and not step == 0: # Calculate elapsed time in minutes. elapsed = format_time(time.time() - t0) # Report progress. print(&#39; Batch {:&gt;5,} of {:&gt;5,}. Elapsed: {:}.&#39;.format(step, len(train_dataloader), elapsed)) # Unpack this training batch from our dataloader. # # As we unpack the batch, we&#39;ll also copy each tensor to the GPU using the # `to` method. # # `batch` contains three pytorch tensors: # [0]: input ids # [1]: attention masks # [2]: labels b_input_ids = batch[0].to(device) b_input_mask = batch[1].to(device) b_labels = batch[2].to(device) # Always clear any previously calculated gradients before performing a # backward pass. PyTorch doesn&#39;t do this automatically because # accumulating the gradients is &quot;convenient while training RNNs&quot;. # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch) model.zero_grad() # Perform a forward pass (evaluate the model on this training batch). # This will return the loss (rather than the model output) because we # have provided the `labels`. # The documentation for this `model` function is here: # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels) # The call to `model` always returns a tuple, so we need to pull the # loss value out of the tuple. loss = outputs[0] # Accumulate the training loss over all of the batches so that we can # calculate the average loss at the end. `loss` is a Tensor containing a # single value; the `.item()` function just returns the Python value # from the tensor. total_loss += loss.item() # Perform a backward pass to calculate the gradients. loss.backward() # Clip the norm of the gradients to 1.0. # This is to help prevent the &quot;exploding gradients&quot; problem. torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Update parameters and take a step using the computed gradient. # The optimizer dictates the &quot;update rule&quot;--how the parameters are # modified based on their gradients, the learning rate, etc. optimizer.step() # Update the learning rate. scheduler.step() # Calculate the average loss over the training data. avg_train_loss = total_loss / len(train_dataloader) # Store the loss value for plotting the learning curve. loss_values.append(avg_train_loss) print(&quot;&quot;) print(&quot; Average training loss: {0:.2f}&quot;.format(avg_train_loss)) print(&quot; Training epcoh took: {:}&quot;.format(format_time(time.time() - t0))) # ======================================== # Validation # ======================================== # After the completion of each training epoch, measure our performance on # our validation set. print(&quot;&quot;) print(&quot;Running Validation...&quot;) t0 = time.time() # Put the model in evaluation mode--the dropout layers behave differently # during evaluation. model.eval() # Tracking variables eval_loss, eval_accuracy = 0, 0 nb_eval_steps, nb_eval_examples = 0, 0 # Evaluate data for one epoch for batch in validation_dataloader: # Add batch to GPU batch = tuple(t.to(device) for t in batch) # Unpack the inputs from our dataloader b_input_ids, b_input_mask, b_labels = batch # Telling the model not to compute or store gradients, saving memory and # speeding up validation with torch.no_grad(): # Forward pass, calculate logit predictions. # This will return the logits rather than the loss because we have # not provided labels. # token_type_ids is the same as the &quot;segment ids&quot;, which # differentiates sentence 1 and 2 in 2-sentence tasks. # The documentation for this `model` function is here: # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) # Get the &quot;logits&quot; output by the model. The &quot;logits&quot; are the output # values prior to applying an activation function like the softmax. logits = outputs[0] # Move logits and labels to CPU logits = logits.detach().cpu().numpy() label_ids = b_labels.to(&#39;cpu&#39;).numpy() # Calculate the accuracy for this batch of test sentences. tmp_eval_accuracy = flat_accuracy(logits, label_ids) # Accumulate the total accuracy. eval_accuracy += tmp_eval_accuracy # Track the number of batches nb_eval_steps += 1 # Report the final accuracy for this validation run. print(&quot; Accuracy: {0:.2f}&quot;.format(eval_accuracy/nb_eval_steps)) print(&quot; Validation took: {:}&quot;.format(format_time(time.time() - t0))) print(&quot;&quot;) print(&quot;Training complete!&quot;) . ======== Epoch 1 / 4 ======== Training... Batch 40 of 168. Elapsed: 0:00:13. Batch 80 of 168. Elapsed: 0:00:26. Batch 120 of 168. Elapsed: 0:00:39. Batch 160 of 168. Elapsed: 0:00:53. Average training loss: 0.69 Training epcoh took: 0:00:56 Running Validation... Accuracy: 0.59 Validation took: 0:00:02 ======== Epoch 2 / 4 ======== Training... Batch 40 of 168. Elapsed: 0:00:14. Batch 80 of 168. Elapsed: 0:00:27. Batch 120 of 168. Elapsed: 0:00:40. Batch 160 of 168. Elapsed: 0:00:54. Average training loss: 0.60 Training epcoh took: 0:00:56 Running Validation... Accuracy: 0.64 Validation took: 0:00:02 ======== Epoch 3 / 4 ======== Training... Batch 40 of 168. Elapsed: 0:00:13. Batch 80 of 168. Elapsed: 0:00:27. Batch 120 of 168. Elapsed: 0:00:40. Batch 160 of 168. Elapsed: 0:00:54. Average training loss: 0.46 Training epcoh took: 0:00:56 Running Validation... Accuracy: 0.64 Validation took: 0:00:02 ======== Epoch 4 / 4 ======== Training... Batch 40 of 168. Elapsed: 0:00:13. Batch 80 of 168. Elapsed: 0:00:27. Batch 120 of 168. Elapsed: 0:00:40. Batch 160 of 168. Elapsed: 0:00:54. Average training loss: 0.34 Training epcoh took: 0:00:56 Running Validation... Accuracy: 0.66 Validation took: 0:00:02 Training complete! . import plotly.express as px f = pd.DataFrame(loss_values) f.columns=[&#39;Loss&#39;] fig = px.line(f, x=f.index, y=f.Loss) fig.update_layout(title=&#39;Training loss of the Model&#39;, xaxis_title=&#39;Epoch&#39;, yaxis_title=&#39;Loss&#39;) fig.show() . . . . Performance On Test Set . Data Preparation . sentences = test_df.sentence.values labels = test_df.label.values . input_ids = [] # For every sentence... for sent in sentences: # `encode` will: # (1) Tokenize the sentence. # (2) Prepend the `[CLS]` token to the start. # (3) Append the `[SEP]` token to the end. # (4) Map tokens to their IDs. encoded_sent = tokenizer.encode( sent, # Sentence to encode. add_special_tokens = True, # Add &#39;[CLS]&#39; and &#39;[SEP]&#39; ) input_ids.append(encoded_sent) # Pad our input tokens input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=&quot;long&quot;, truncating=&quot;post&quot;, padding=&quot;post&quot;) # Create attention masks attention_masks = [] # Create a mask of 1s for each token followed by 0s for padding for seq in input_ids: seq_mask = [float(i&gt;0) for i in seq] attention_masks.append(seq_mask) # Convert to tensors. prediction_inputs = torch.tensor(input_ids) prediction_masks = torch.tensor(attention_masks) prediction_labels = torch.tensor(labels) # Set the batch size. batch_size = 16 # Create the DataLoader. prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels) prediction_sampler = SequentialSampler(prediction_data) prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size) . Evaluate on Test Set . print(&#39;Predicting labels for {:,} test sentences...&#39;.format(len(prediction_inputs))) # Put model in evaluation mode model.eval() # Tracking variables predictions , true_labels = [], [] # Predict for batch in prediction_dataloader: # Add batch to GPU batch = tuple(t.to(device) for t in batch) # Unpack the inputs from our dataloader b_input_ids, b_input_mask, b_labels = batch # Telling the model not to compute or store gradients, saving memory and # speeding up prediction with torch.no_grad(): # Forward pass, calculate logit predictions outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) logits = outputs[0] # Move logits and labels to CPU logits = logits.detach().cpu().numpy() label_ids = b_labels.to(&#39;cpu&#39;).numpy() # Store predictions and true labels predictions.append(logits) true_labels.append(label_ids) print(&#39;DONE.&#39;) . Predicting labels for 743 test sentences... DONE. . print(&#39;Positive samples: %d of %d (%.2f%%)&#39; % (test_df.label.sum(), len(test_df.label), (test_df.label.sum() / len(test_df.label) * 100.0))) . Positive samples: 325 of 743 (43.74%) . true_labels[0] . array([1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]) . sum_list = [] for i in range(0, len(predictions)): sum_list.append(flat_accuracy(predictions[i], true_labels[i])) . avg_acc = np.mean(sum_list) print(&#39;테스트 셋에서의 accuracy :&#39;, avg_acc) . 테스트 셋에서의 accuracy : 0.6065729483282675 . pred_flat = np.argmax(predictions[0], axis=1).flatten() . pred_flat . array([0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]) . true_labels[0] . array([1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]) . PART 2! MINDS &#45936;&#51060;&#53552;&#49483; . 이제 IBC 데이터셋으로 훈련시킨 정치 성향 판별 모델로 MINDS 데이터셋의 정치 카테고리 기사들의 정치 성향을 디텍딩한다. . 1. &#45936;&#51060;&#53552;&#49483; &#51456;&#48708; . train_poli = pd.read_csv(&#39;/content/train_politic.csv&#39;) test_poli = pd.read_csv(&#39;/content/test_politic.csv&#39;) . train_poli.head(3) . News ID Category Subcategory Title Abstract URL Title Entities Abstract Entities . 0 N9786 | news | newspolitics | Elijah Cummings to lie in state at US Capitol ... | Cummings, a Democrat whose district included s... | https://assets.msn.com/labs/mind/AAJgNxm.html | [{&quot;Label&quot;: &quot;Elijah Cummings&quot;, &quot;Type&quot;: &quot;P&quot;, &quot;Wi... | [{&quot;Label&quot;: &quot;Elijah Cummings&quot;, &quot;Type&quot;: &quot;P&quot;, &quot;Wi... | . 1 N47214 | news | newspolitics | Here are the lawmakers who are not seeking ree... | The battle for control of Congress is more tha... | https://assets.msn.com/labs/mind/AAFcidm.html | [] | [] | . 2 N24905 | news | newspolitics | Grieder: Special election in House District 28... | The special election in Texas House District 2... | https://assets.msn.com/labs/mind/AAJJa4h.html | [{&quot;Label&quot;: &quot;2004 North Carolina General Assemb... | [{&quot;Label&quot;: &quot;Republican Party (United States)&quot;,... | . train_poli.columns . Index([&#39;News ID&#39;, &#39;Category&#39;, &#39;Subcategory&#39;, &#39;Title&#39;, &#39;Abstract&#39;, &#39;URL&#39;, &#39;Title Entities&#39;, &#39;Abstract Entities&#39;], dtype=&#39;object&#39;) . print(&#39;훈련 데이터셋 크기 : &#39;, len(train_poli)) print(&#39;테스트 데이터셋 크기 : &#39;, len(test_poli)) . 훈련 데이터셋 크기 : 2831 테스트 데이터셋 크기 : 2402 . train_poli.isnull().sum() . News ID 0 Category 0 Subcategory 0 Title 0 Abstract 66 URL 0 Title Entities 0 Abstract Entities 0 dtype: int64 . test_poli.isnull().sum() . News ID 0 Category 0 Subcategory 0 Title 0 Abstract 63 URL 0 Title Entities 0 Abstract Entities 0 dtype: int64 . train_poli = train_poli.dropna(axis=0) test_poli = test_poli.dropna(axis=0) . print(&#39;훈련 데이터셋 크기 : &#39;, len(train_poli)) print(&#39;테스트 데이터셋 크기 : &#39;, len(test_poli)) . 훈련 데이터셋 크기 : 2765 테스트 데이터셋 크기 : 2339 . Title과 Abstract 칼럼을 합친 &#39;TitleAbstract&#39; 칼럼을 추가한다. ==&gt; 추후 이 칼럼 데이터로 정치 성향을 판단 . train_poli[&#39;TitleAbstract&#39;] = train_poli[&#39;Title&#39;] + &#39; &#39; + train_poli[&#39;Abstract&#39;] . test_poli[&#39;TitleAbstract&#39;] = test_poli[&#39;Title&#39;] + &#39; &#39; + test_poli[&#39;Abstract&#39;] . train_poli.head(3) . News ID Category Subcategory Title Abstract URL Title Entities Abstract Entities TitleAbstract . 0 N9786 | news | newspolitics | Elijah Cummings to lie in state at US Capitol ... | Cummings, a Democrat whose district included s... | https://assets.msn.com/labs/mind/AAJgNxm.html | [{&quot;Label&quot;: &quot;Elijah Cummings&quot;, &quot;Type&quot;: &quot;P&quot;, &quot;Wi... | [{&quot;Label&quot;: &quot;Elijah Cummings&quot;, &quot;Type&quot;: &quot;P&quot;, &quot;Wi... | Elijah Cummings to lie in state at US Capitol ... | . 1 N47214 | news | newspolitics | Here are the lawmakers who are not seeking ree... | The battle for control of Congress is more tha... | https://assets.msn.com/labs/mind/AAFcidm.html | [] | [] | Here are the lawmakers who are not seeking ree... | . 2 N24905 | news | newspolitics | Grieder: Special election in House District 28... | The special election in Texas House District 2... | https://assets.msn.com/labs/mind/AAJJa4h.html | [{&quot;Label&quot;: &quot;2004 North Carolina General Assemb... | [{&quot;Label&quot;: &quot;Republican Party (United States)&quot;,... | Grieder: Special election in House District 28... | . train_poli.TitleAbstract[0] . &#39;Elijah Cummings to lie in state at US Capitol Thursday Cummings, a Democrat whose district included sections of Baltimore, died last week at age 68 from complications related to longstanding health issues.&#39; . sentences = train_poli.TitleAbstract.values . sentences[-1] . &#39;High-stakes televised impeachment hearings set for next week William Taylor, the top diplomat in Ukraine, will testify, and Republicans hope to hear from Hunter Biden and the anonymous whistleblower.&#39; . 2. &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; (&#53664;&#53356;&#45208;&#51060;&#51669;, &#54056;&#46377;, &#50612;&#53584;&#49496; &#47560;&#49828;&#53356;, &#45936;&#51060;&#53552;&#49483; &#47196;&#46300;) . 가장 긴 문장이 토큰 445개짜리 문장... 적당히 300을 MAX_LEN으로 지정 . input_ids = [] # For every sentence... for sent in sentences: # `encode` will: # (1) Tokenize the sentence. # (2) Prepend the `[CLS]` token to the start. # (3) Append the `[SEP]` token to the end. # (4) Map tokens to their IDs. encoded_sent = tokenizer.encode( sent, # Sentence to encode. add_special_tokens = True, # Add &#39;[CLS]&#39; and &#39;[SEP]&#39; ) input_ids.append(encoded_sent) # Pad our input tokens input_ids = pad_sequences(input_ids, maxlen=300, dtype=&quot;long&quot;, truncating=&quot;post&quot;, padding=&quot;post&quot;) . print(&#39;Original: &#39;, sentences[1]) print(&#39;Token IDs:&#39;, input_ids[1]) . Original: Here are the lawmakers who are not seeking reelection to Congress in 2020 The battle for control of Congress is more than a year away but some lawmakers are already deciding not to run for reelection, setting up a few potentially interesting campaigns in the 2020 election. Token IDs: [ 101 2182 2024 1996 2375 12088 2040 2024 2025 6224 17648 2000 3519 1999 12609 1996 2645 2005 2491 1997 3519 2003 2062 2084 1037 2095 2185 2021 2070 2375 12088 2024 2525 10561 2025 2000 2448 2005 17648 1010 4292 2039 1037 2261 9280 5875 8008 1999 1996 12609 2602 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] . attention_masks = [] # Create a mask of 1s for each token followed by 0s for padding for seq in input_ids: seq_mask = [float(i&gt;0) for i in seq] attention_masks.append(seq_mask) # Convert to tensors. prediction_inputs = torch.tensor(input_ids) prediction_masks = torch.tensor(attention_masks) # Set the batch size. batch_size = 16 # Create the DataLoader. prediction_data = TensorDataset(prediction_inputs, prediction_masks) prediction_sampler = SequentialSampler(prediction_data) prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size) . Detect Ideology of News Text . print(&#39;Detecting ideology labels for {:,} news sentences...&#39;.format(len(prediction_inputs))) # Put model in evaluation mode model.eval() # Tracking variables predictions = [] # Predict for batch in prediction_dataloader: # Add batch to GPU batch = tuple(t.to(device) for t in batch) # Unpack the inputs from our dataloader b_input_ids, b_input_mask = batch # Telling the model not to compute or store gradients, saving memory and # speeding up prediction with torch.no_grad(): # Forward pass, calculate logit predictions outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) logits = outputs[0] # Move logits and labels to CPU logits = logits.detach().cpu().numpy() #label_ids = b_labels.to(&#39;cpu&#39;).numpy() # Store predictions and true labels predictions.append(logits) #true_labels.append(label_ids) print(&#39;DONE.&#39;) . Detecting ideology labels for 2,765 news sentences... DONE. . len(predictions) . 173 . ideology_list = [] for i in range(len(predictions)): pred_flat = np.argmax(predictions[i], axis=1).flatten() pred_flat = pred_flat.tolist() ideology_list += pred_flat . len(ideology_list) # 2765. 트레인 데이터셋에 들어있는 2763개 뉴스에 대한 정치 detection labeling을 했다. . 2765 . type(ideology_list) . list . 뉴스-정치 라벨링 짝을 쉽게 보기 위해 데이터 프레임에 &#39;Ideology&#39; 칼럼으로 추가한다. . train_poli[&#39;Ideology&#39;] = ideology_list . train_poli.head(3) . News ID Category Subcategory Title Abstract URL Title Entities Abstract Entities TitleAbstract Ideology . 0 N9786 | news | newspolitics | Elijah Cummings to lie in state at US Capitol ... | Cummings, a Democrat whose district included s... | https://assets.msn.com/labs/mind/AAJgNxm.html | [{&quot;Label&quot;: &quot;Elijah Cummings&quot;, &quot;Type&quot;: &quot;P&quot;, &quot;Wi... | [{&quot;Label&quot;: &quot;Elijah Cummings&quot;, &quot;Type&quot;: &quot;P&quot;, &quot;Wi... | Elijah Cummings to lie in state at US Capitol ... | 1 | . 1 N47214 | news | newspolitics | Here are the lawmakers who are not seeking ree... | The battle for control of Congress is more tha... | https://assets.msn.com/labs/mind/AAFcidm.html | [] | [] | Here are the lawmakers who are not seeking ree... | 0 | . 2 N24905 | news | newspolitics | Grieder: Special election in House District 28... | The special election in Texas House District 2... | https://assets.msn.com/labs/mind/AAJJa4h.html | [{&quot;Label&quot;: &quot;2004 North Carolina General Assemb... | [{&quot;Label&quot;: &quot;Republican Party (United States)&quot;,... | Grieder: Special election in House District 28... | 0 | . 2.4 &#47784;&#45944; &#49457;&#45733; &#54217;&#44032; . 2.4.1 IBC &#45936;&#51060;&#53552;&#47484; &#51060;&#50857;&#54620; &#54217;&#44032; . 위에서 확인할 수 있듯 모델은 검증 데이터세트에서 정확도 최대 0.66을 보여줬다. 테스트 데이터세트에서의 정확도는 약 0.60을 기록했다. . 2.4.2 &#48324;&#46020; &#45684;&#49828; &#45936;&#51060;&#53552;&#47484; &#51060;&#50857;&#54620; &#54217;&#44032; . 모델 성능을 살피기 위한 두 번째 방법으로 AllSides 사이트가 제공하는 AllSides Media Bias Ratings가 평가한 미디어 정치 성향 평가를 활용했다. . . AllSides Media Bias Ratings는 온라인 사용자들에게 미국 온라인 매체들의 정치 성향을 5개 단계(진보 편향 - 진보 - 중도 - 보수 - 보수 편향) 중 하나로 라벨링 하게 하고, 라벨링에 대한 커뮤니티 피드백을 6개 단계(absolutely disagree - somewhat disagree - disagree - somewhat agree - agree - absolutely agree)로 제공한다. . . 이 서비스를 참고해 정치 성향 평가에 대한 커뮤니티 피드백 단계 중 absolutely agree를 받은 진보 편향 매체 2개(AlterNet, The New Yorker)와 보수 편향 매체 2개(National Review, The Federalist), 총 4개 매체를 골랐다. 그리고 각 매체의 최근 정치 기사의 첫 문장을 발췌해 우리의 모델로 정치 성향을 탐지해, 그 결과가 집단지성이 탐지한 정치 성향과 일치 여부를 살펴보았다. . BERT &#54028;&#51064;&#53916;&#45789;&#51004;&#47196; &#47564;&#46304; &#51221;&#52824; &#49457;&#54693; &#54032;&#48324; &#47784;&#45944;, &#51221;&#47568; &#48127;&#51012;&#47564;..&#54620;&#44032;? . 정성 평가를 해보자 https://www.allsides.com/media-bias/media-bias-ratings . test_news = pd.read_excel(&#39;/content/news_Lib_and_Con.xlsx&#39;) test_news.to_csv(r&#39;/content/news_Lib_and_Con.csv&#39;, index=None) . test_news . Press Sentence Ideology_label_by_media_bias Ideology_label_by_our_model link . 0 AlterNet | On Tuesday, writing for The Daily Beast, forme... | 0 | NaN | https://www.alternet.org/2021/02/capitol-riot-... | . 1 AlterNet | Democrats are currently negotiating with thems... | 0 | NaN | https://www.alternet.org/2021/02/manchin-biden/ | . 2 AlterNet | Hours after President Biden declared that &quot;dem... | 0 | NaN | https://www.alternet.org/2021/01/republican-el... | . 3 NationalReview | Last week, just as Texas was set to officially... | 1 | NaN | https://www.nationalreview.com/corner/district... | . 4 NationalReview | For the third year in a row, Senate Democrats ... | 1 | NaN | https://www.nationalreview.com/2021/02/democra... | . 5 NationalReview | Conservatism is having an identity crisis When... | 1 | NaN | https://www.nationalreview.com/2021/02/the-con... | . 6 TheFederalist | Democrats Distract Federal Government With ‘Gr... | 1 | NaN | https://thefederalist.com/2021/02/09/democrats... | . 7 TheFederalist | So the petty little fascists in the Democratic... | 1 | NaN | https://thefederalist.com/2021/02/08/this-impe... | . 8 TheFederalist | The conservative mindset may be to despair rig... | 1 | NaN | https://thefederalist.com/2021/02/09/exclusive... | . 9 TheNewYorker | As tens of thousands of Americans continue to ... | 0 | NaN | https://www.newyorker.com/news/our-columnists/... | . 10 TheNewYorker | Last week’s storming of the Capitol attracted ... | 0 | NaN | https://www.newyorker.com/news/news-desk/a-for... | . 11 TheNewYorker | Donald Trump is no longer the President of the... | 0 | NaN | https://www.newyorker.com/news/our-columnists/... | . sentences = test_news.Sentence.values . 모델에 넣기 위한 데이터 형태로 변환 . input_ids = [] # For every sentence... for sent in sentences: # `encode` will: # (1) Tokenize the sentence. # (2) Prepend the `[CLS]` token to the start. # (3) Append the `[SEP]` token to the end. # (4) Map tokens to their IDs. encoded_sent = tokenizer.encode( sent, # Sentence to encode. add_special_tokens = True, # Add &#39;[CLS]&#39; and &#39;[SEP]&#39; ) input_ids.append(encoded_sent) # Pad our input tokens input_ids = pad_sequences(input_ids, maxlen=300, dtype=&quot;long&quot;, truncating=&quot;post&quot;, padding=&quot;post&quot;) # Create attention masks attention_masks = [] # Create a mask of 1s for each token followed by 0s for padding for seq in input_ids: seq_mask = [float(i&gt;0) for i in seq] attention_masks.append(seq_mask) # Convert to tensors. prediction_inputs = torch.tensor(input_ids) prediction_masks = torch.tensor(attention_masks) # Set the batch size. batch_size = 16 # Create the DataLoader. prediction_data = TensorDataset(prediction_inputs, prediction_masks) prediction_sampler = SequentialSampler(prediction_data) prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size) . 모델을 이용한 정치 성향 detecting . print(&#39;Detecting ideology labels for {:,} news sentences...&#39;.format(len(prediction_inputs))) # Put model in evaluation mode model.eval() # Tracking variables predictions = [] # Predict for batch in prediction_dataloader: # Add batch to GPU batch = tuple(t.to(device) for t in batch) # Unpack the inputs from our dataloader b_input_ids, b_input_mask = batch # Telling the model not to compute or store gradients, saving memory and # speeding up prediction with torch.no_grad(): # Forward pass, calculate logit predictions outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) logits = outputs[0] # Move logits and labels to CPU logits = logits.detach().cpu().numpy() #label_ids = b_labels.to(&#39;cpu&#39;).numpy() # Store predictions and true labels predictions.append(logits) #true_labels.append(label_ids) print(&#39;DONE.&#39;) . Detecting ideology labels for 12 news sentences... DONE. . ideology_list = [] for i in range(len(predictions)): pred_flat = np.argmax(predictions[i], axis=1).flatten() pred_flat = pred_flat.tolist() ideology_list += pred_flat . test_news.Ideology_label_by_our_model = ideology_list . test_news . Press Sentence Ideology_label_by_media_bias Ideology_label_by_our_model link . 0 AlterNet | On Tuesday, writing for The Daily Beast, forme... | 0 | 1 | https://www.alternet.org/2021/02/capitol-riot-... | . 1 AlterNet | Democrats are currently negotiating with thems... | 0 | 0 | https://www.alternet.org/2021/02/manchin-biden/ | . 2 AlterNet | Hours after President Biden declared that &quot;dem... | 0 | 0 | https://www.alternet.org/2021/01/republican-el... | . 3 NationalReview | Last week, just as Texas was set to officially... | 1 | 1 | https://www.nationalreview.com/corner/district... | . 4 NationalReview | For the third year in a row, Senate Democrats ... | 1 | 0 | https://www.nationalreview.com/2021/02/democra... | . 5 NationalReview | Conservatism is having an identity crisis When... | 1 | 1 | https://www.nationalreview.com/2021/02/the-con... | . 6 TheFederalist | Democrats Distract Federal Government With ‘Gr... | 1 | 1 | https://thefederalist.com/2021/02/09/democrats... | . 7 TheFederalist | So the petty little fascists in the Democratic... | 1 | 1 | https://thefederalist.com/2021/02/08/this-impe... | . 8 TheFederalist | The conservative mindset may be to despair rig... | 1 | 1 | https://thefederalist.com/2021/02/09/exclusive... | . 9 TheNewYorker | As tens of thousands of Americans continue to ... | 0 | 0 | https://www.newyorker.com/news/our-columnists/... | . 10 TheNewYorker | Last week’s storming of the Capitol attracted ... | 0 | 0 | https://www.newyorker.com/news/news-desk/a-for... | . 11 TheNewYorker | Donald Trump is no longer the President of the... | 0 | 1 | https://www.newyorker.com/news/our-columnists/... | . 12개 중 9개 딕텍션 성공 . 그 결과, 12개 중 9개 문장에 대한 정치 성향 탐지에 성공해 75% 정확도를 보였다. . 3. &#54596;&#53552;&#48260;&#48660;&#51012; &#53552;&#46888;&#47532;&#45716; &#45684;&#49828; &#52628;&#52380; &#49884;&#49828;&#53596; . 이제 앞에서 만든 텍스트의 정치 성향 분류 모델에 콘텐츠 추천 알고리즘을 더한 뉴스 추천 시스템을 제안한다. . 이에 뉴스 기사 추천 알고리즘 중 DKN(Deep Knowledge-Aware Network for News Recommendation)을 사용자가 가장 좋아할 만한 기사를 추천해주는 기존의 방식으로 학습하고, 이를 앞서 개발한 텍스트 정치 성향 탐지 모델과 결합하여 필터버블을 완화할 수 있는 추천 모형을 제안한다. . 3.1 &#54984;&#47144; &#45936;&#51060;&#53552; - MIND . 추천 알고리즘 학습에 MIND((A Large Scale Dataset for News Recommendation)) 데이터세트을 사용하였다. MIND는 Microsoft에서 뉴스 추천 알고리즘의 연구를 위해 공개한 데이터로, Microsoft News에서 수집한 100만 명의 사용자와 160,000건의 기사 정보로 이루어져 있다. 수집 기간은 2019.10.12 부터 2019.11.22.까지 총 6주이다. 사용자 정보는, 각 사용자의 익명화된 아이디와 그들이 클릭한 기사 로그 기록을 포함하고, 기사 정보는 기사 아이디와 category, title, abstract을 포함한다. 본 프로젝트에서는 전체 데이터 중 5만 명의 사용자를 샘플링한 MIND-small 데이터세트을 사용하였다. 추천 알고리즘 학습에는 기사 정보 중 title만 사용하였고, 마지막 추천 단계에서는 정치 기사만 남겨서, title과 abstract 텍스트를 정치 성향 탐지 모델에 사용하였다. . 3.2 &#52628;&#52380; &#50508;&#44256;&#47532;&#51608; - DKN . 3.2.1 &#50508;&#44256;&#47532;&#51608; &#49440;&#51221; &#51060;&#50976; . DKN(Deep Knowledge-Aware Network for News Recommendation)은 뉴스 텍스트 엔티티의 지식그래프 구조를 활용한 콘텐츠 기반 추천 알고리즘이다. 뉴스 추천을 위한 다양한 알고리즘 중 DKN을 선정한 이유는 두 가지 이다. 첫째, 뉴스 기사는 음악, 영화 등 다른 콘텐츠에 비해 수명이 매우 짧아서 협업필터링보다는 콘텐츠기반 필터링이 보다 효과적이다. MIND 데이터세트의 경우도 대부분의 기사가 2일 이내에 클릭률이 0으로 떨어지는 모습이 나타났다. 둘째, 기사의 ‘논조’를 반영하기 위해서는 지식 그래프 구조가 효과적일 수 있다고 보았다. 논조는 단어들이 어떠한 구조로 연결되었는가에 의해 결정되기 때문이다. . 3.2.2. &#50508;&#44256;&#47532;&#51608; &#49444;&#47749; . DKN은 KCNN(Knowledge-aware Convolutional Neural Network)를 통한 기사 임베딩과, 사용자별 로그 기록을 사용한 attention network의 두 단계를 통해 이루어진다. 후보 기사 하나와, 사용자의 로그 기록을 인풋으로 하여, 해당 사용자가 후보 기사를 읽을 확률을 예측하고 실제 사용자가 그 기사를 읽었는지 여부와 비교하는 방식으로 학습한다. . 먼저, KCNN은 텍스트를 word embedding, entity embedding, context embedding의 3가지 채널로 표현하여 CNN을 통해 특징을 추출하는 것이다. 텍스트를 3채널로 표현하는 방식은 다음과 같다. 예를 들어, &quot;Donald Trump to deliver State of the Union address next week&quot; 이라는 기사 제목이 있다면, 이 텍스트는 단어 수준에서는 [10, 34,45,334,23,12,987,3456,111,456,432]와 같이 인코딩 되고, 첫 번째 단어와 두 번째 단어인 ‘Donald Trump’가 한 개의 엔티티로 추출되어 엔티티 수준에서는 [45, 45,0,0,0,0,0,0,0,0,0]와 같이 인코딩 된다. 단어와 엔티티 수준에서 인코딩된 텍스트 인풋을 가지고 word embedding, entity embedding, context embedding을 추출한다. word embedding은 word2vec, Glove 등의 방식을 사용하여 단어를 임베딩 하는 것으로, 이번 프로젝트에서는 사전 학습(pre-trained) Glove를 통해 word embedding initialization을 설정하였다. entity embedding과 context embedding은 지식 그래프를 사용한다. 문장에서 엔티티를 찾아내어 지식그래프와 매칭시키는 entity linking 이후, corpus의 엔티티 중 1단계 내로 이어진 엔티티를 연결하여 corpus의 sub-graph를 얻는다. 다음으로 TransE를 사용한 네트워크 임베딩을 실시하여 각 entity embedding을 얻는다. 또한 엔티티별로 한 단계로 연결된 엔티티의 임베딩을 평균낸 context embedding을 얻는다. entity embedding과 context embedding을 통해 단어의 정보 뿐 아니라 텍스트의 엔티티들이 서로 어떠한 관계를 가지고 있는지 까지 반영할 수 있게 된다. 이렇게 얻어진 word-embedding, entity embedding, context-embedding을 3가지의 채널로 쌓아, 컬러 이미지에 적용하는 것과 같은 3-channel CNN을 텍스트에 적용하여 특징을 추출하여 기사 별 1차원의 임베딩 벡터를 얻는다. . 기사별 임베딩을 얻은 후에는, 사용자의 기록을 고려한 attention network를 거쳐 사용자가 후보 기사를 읽었는지 예측한다. 사용자의 로그 기록에 해당하는 기사들의 임베딩 벡터와 후보기사의 임베딩 벡터에 어텐션을 적용해, 로그 기록 각 기사에 대해 후보 기사에 대한 어텐션 가중치를 구한다. 다음으로 로그 기록 기사 임베딩을 가중 평균 내어 사용자의 임베딩 벡터를 넣는다. 마지막으로 후보 기사의 임베딩과 사용자 임베딩을 concat하여 해당 사용자가 후보 기사를 읽을 확률을 예측한다. . 3.3 &#53552;&#48260;&#48660;&#51012; &#53552;&#46888;&#47532;&#44592; &#50948;&#54620; &#52628;&#52380;&#49884;&#49828;&#53596; &#44060;&#48156; &#44284;&#51221; &#48143; &#44208;&#44284; . DKN을 사용하는 경우, 두 가지 방식의 추천이 가능하다. 사용자의 이전 기록을 모두 고려하여 추천 기사 리스트를 묶어서 제공할 수도 있고, DKN 학습 과정에서 추출된 각 기사 별 임베딩을 사용하여 사용자가 지금 당장 읽고 있는 기사와 관련된 글을 추천(item2item방식)할 수도 있다. 본 프로젝트에서는 후자의 방식을 이용하고자 한다. 추천 모델은 MIND-small 데이터를 모두 사용하여 학습하였으나, 추천 과정에서는 논조의 차이가 가장 두드러지게 나타나는 정치기사만 사용하였다. 전체 기사 중 정치 카테고리에 속하고, title과 abstract이 모두 존재하는 3393개의 기사를 대상으로 필터버블을 터뜨리기 위한 추천을 실험해보았다. . 첫째, DKN을 통해 각 기사의 단어, 엔티티 구조가 담긴 기사 별 KCNN 임베딩을 얻는다. 둘째, KCNN 임베딩으로 코사인 유사도를 계산하여 특정 기사와 비슷한 기사를 찾는다. 코사인 유사도가 높은 기사를 살펴본 결과, 실제로 비슷한 주제를 다루고 있음을 알 수 있었다. 셋째, 정치성향 분류모델을 사용하여 추천 대상이 되는 기사와 유사도는 높으면서 정치 성향은 다르게 예측된 기사를 추천한다. 정치성향 분류 모델 적용 결과 3393개의 기사 중 1745개가 liberal, 1648개가 conservative로 분류되었다. 이 과정을 통해 정치 기사에 대하여, 비슷한 주제를 다루면서도 논조가 다른 기사를 추천하고자 하였다. . 실험 결과의 예시로 두 가지 사례를 제시한다. 첫 번째 사례는 “The Many Ways That Joe Biden Trips Over His Own Tongue” 기사이다. 해당 기사는 정치 성향 분류 모델에서 ‘conservative’로 분류되었으며, Joe Biden이 이민자 정책에 대해 말을 바꾼 것에 대한 비판 내용을 담고 있다. 한편 KCNN 임베딩으로 계산한 코사인 유사도가 두 번째로 높은 ‘Latino Iowans are playing a bigger role in the caucuses and Democrats are paying attention’ 기사는 정치 성향 분류 모델에서 ‘liberal’로 분류되었다. 추천 대상 기사와 유사하게 BIden의 이민자 정책에 대해 다루고 있지만, 논조는 바이든의 이민자 정책이 Iowa 라틴계 유권자들의 마음을 이끌고 있다는 긍정적인 내용이다. 따라서 주제는 비슷하지만 논조가 다른 이 기사를 함께 추천할 수 있다. . 두 번째 사례는 “Warren&#39;s $52T &#39;Medicare-for-all&#39; plan revealed: Campaign still claims no middle-class tax hikes needed” 기사이다. 해당 기사는 정치 성향 분류 모델에서 ‘liberal’로 분류 되었으며, 민주당 대선 후보인 Warren의 ‘Medicare-for-all’ 정책이 중산층 세금 인상을 필요로 하지 않는다는 내용을 담고 있다. 한편 코사인 유사도가 2번째로 높지만, 정치 성향 분류 모델에서 ‘conservative’로 분류된 ‘Warren&#39;s health care plan pledges no middle-class tax increase’은 같은 주제를 다루면서도, 실제로는 세금 인상 없이 정책을 실행하기는 무리라는 주장을 하고 있다. 따라서 이 기사를 함께 추천할 수 있다. . import torch import torch.nn.functional as F def train(model, train_loader, loss_func, optimizer, step, print_step=200): &quot;&quot;&quot;train function&quot;&quot;&quot; model.train() for i, batch in enumerate(train_loader): inputs, targets = batch.sentence, batch.label.float() targets = targets.long() # 경사 초기화 optimizer.zero_grad() # 순방향 전파 outputs = model(inputs) # 손실값 계산 loss = loss_func(outputs, targets) # 역방향 전파 loss.backward() # 매개변수 업데이트 optimizer.step() print(&#39;Train Step: {} ({:05.2f}%) tLoss: {:.4f}&#39;.format( step, 100.*(i*train_loader.batch_size)/len(train_loader.dataset), loss.item())) def test(model, test_loader, loss_func): &quot;&quot;&quot;test function&quot;&quot;&quot; # 모델에게 평가단계이라고 선언함 model.eval() test_loss = 0 correct = 0 with torch.no_grad(): for batch in test_loader: inputs, targets = batch.sentence, batch.label.float() targets = targets.long() # 순방향전파 outputs = model(inputs) # 손실값 계산(합) test_loss += loss_func(outputs, targets).item() # 예측값 preds = outputs.softmax(1) print(preds) preds = preds.argmax(dim=1) # 정확하게 예측한 개수를 기록한다 correct += preds.eq(targets).sum().item() test_loss /= len(test_loader.dataset) test_acc = correct / len(test_loader.dataset) print(&#39;Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:05.2f}%)&#39;.format( test_loss, correct, len(test_loader.dataset), 100. * test_acc)) return test_loss, test_acc def main(model, train_loader, test_loader, loss_func, optimizer, n_step, save_path=None, print_step=30): &quot;&quot;&quot;메인 학습 함수&quot;&quot;&quot; test_accs = [] best_acc = 0.0 for step in range(1, n_step+1): # 훈련 단계 train(model, train_loader, loss_func, optimizer, step=step, print_step=print_step) # 평가 단계 test_loss, test_acc = test(model, test_loader, loss_func=torch.nn.CrossEntropyLoss(reduction=&#39;sum&#39;)) # 테스트 정확도 기록 test_accs.append(test_acc) # 모델 최적의 매개변수값을 저장할지 결정하고 기록한다. if len(test_accs) &gt;= 2: if test_acc &gt;= best_acc: best_acc = test_acc best_state_dict = model.state_dict() print(&quot;discard previous state, best model state saved!&quot;) print(&quot;&quot;) # 매개변수 값 저장하기 if save_path is not None: torch.save(best_state_dict, save_path) . import torch import torch.nn as nn import torch.optim as optim from torchtext.data import Field, TabularDataset, Iterator from train_utils_nlp import main # 전처리 source_folder = &#39;./data&#39; label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.long, is_target=True) text_field = Field(tokenize=&#39;spacy&#39;, lower=True, batch_first=True) fields = [ (&#39;label&#39;, label_field), (&#39;sentence&#39;, text_field)] train, test = TabularDataset.splits(path=source_folder, train=&#39;train.csv&#39;, test=&#39;test.csv&#39;, format=&#39;CSV&#39;, fields=fields, skip_header=True) text_field.build_vocab(train, test, min_freq=2) batch_size = 128 device = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39; epoch = 100 train_loader = Iterator(dataset=train, batch_size=batch_size, device=device) test_loader = Iterator(dataset=test, batch_size=batch_size, device=device) # 모델 만들기 class IdeologyCls(nn.Module): def __init__(self, vocab_size, embed_size, hidden_size, output_size, num_layers=1, batch_first=True, bidirec=True): super(IdeologyCls, self).__init__() self.hidden_size = hidden_size self.n_layers = num_layers self.n_direct = 2 if bidirec else 1 self.embedding_layer = nn.Embedding(vocab_size, embed_size) self.rnn_layer = nn.LSTM(input_size=embed_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=batch_first, bidirectional=bidirec) self.linear = nn.Linear(self.n_direct*hidden_size, output_size) def forward(self, x): embeded = self.embedding_layer(x) hidden, cell = self.init_hiddens(x.size(0), self.hidden_size, device=x.device) output, (hidden, cell) = self.rnn_layer(embeded, (hidden, cell)) last_hidden = torch.cat([h for h in hidden[-self.n_direct:]], dim=1) scores = self.linear(last_hidden) scores = torch.softmax(scores, dim=1) return scores def init_hiddens(self, batch_size, hidden_size, device): hidden = torch.zeros(self.n_direct*self.n_layers, batch_size, hidden_size) cell = torch.zeros(self.n_direct*self.n_layers, batch_size, hidden_size) return hidden.to(device), cell.to(device) embed_size = 16 hidden_size = 32 output_size = 3 num_layers = 3 batch_first = True bidirec = True lr = 0.000001 model = IdeologyCls(vocab_size=len(text_field.vocab), embed_size=embed_size, hidden_size=hidden_size, output_size=output_size, num_layers=num_layers, batch_first=batch_first, bidirec=bidirec).to(device) loss_function = nn.NLLLoss() optimizer = optim.Adam(model.parameters(), lr=lr) main(model=model, train_loader=train_loader, test_loader=test_loader, loss_func=loss_function, optimizer=optimizer, n_step=epoch, save_path=&#39;./model/&#39;, print_step=256) . 4. &#45224;&#45716; &#51656;&#47928;&#46308;&#44284; &#50526;&#51004;&#47196;&#51032; &#44228;&#54925; . 위에서 제안한 방법은 같은 사안을 다룬 기사 중 정치성향이 상반된 기사를 추천하는 방식이다. 그 성능에 대한 평가를 차치하고서라도 남는 질문이 있다. 과연 이 방법이 필터버블을 터뜨리는 데 유효할 것인가? 콜럼비아 대학과 뉴욕 대학이 공동 연구한 결과에 따르면, 소셜미디어에서 반대 정치 성향에 노출되면 오히려 정치 양극화가 심화된다고 한다. (자세한 내용은 이 글을 참고 : Exposure to opposing views on social media can increase political polarization) 예상 가능하듯, backfire 때문이다. . 사실 이 지점을 POP THE FILTER BUBBLE을 시작할 때부터 우려한 점이다. 때문에 처음 디자인 한 모델은 정치 성향을 0과 1, 바이너리로 분류하는 것이 아니라 0~1 사이 확률값으로 구하는 것이었다. 궁극적으로는 독자가 자신이 읽고 있는 기사가 0(진보)과 1(보수) 사이 숫자로 표현된 정치 성향 바(bar)에서 어느 지점에 위치하는 지 확인하고, 바에서 정치 성향 포인트를 바꿔가며 다양한 정치 성향을 가진 유사 소재 기사를 선택해 읽게 하는 것이었다. . 5. &#52280;&#44256; &#47928;&#54732; . The Filter Bubble - How the new personalized web is changing what we read and how we think (2012.04, Eli Pariser) | Political Ideology Detection Using Recursive Neural Networks (2014.06, Mohit Iyyer 외 3인, ACL Anthology) | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding(2019.05, Jacob Devlin 외 4인, arVic) | DKN: Deep Knowledge-Aware Network for News Recommendation(2018.04, H Wang, F Zhang, X Xie, M Guo) | MIND: A Large-scale Dataset for News Recommendation(2020.07, F Wu, Y Qiao, JH Chen, C Wu, T Qi, J Lian) | . &lt;/div&gt; .",
            "url": "https://bibliophileryu.github.io/RyuHan/bert/filter_bubble/torch/nlp/journalism/2021/07/08/POP_THE_FILTER_BUBBLE_(1).html",
            "relUrl": "/bert/filter_bubble/torch/nlp/journalism/2021/07/08/POP_THE_FILTER_BUBBLE_(1).html",
            "date": " • Jul 8, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "이 판결문의 '성인지 감수성 점수'는 N점입니다!",
            "content": "이 프로젝트는 @레이첼 외 1인과 함께 한 것임을 밝힙니다. . 판결문의 성인지 감수성 탐지 프로젝트는 n번방 사건을 접하며 시작했다. . n번방은 판결을 먹고 자랐다 . 성범죄 솜방망이 처벌이 심각하다 . 판사들은 방조자와 다름없다 . 사회 곳곳에서 위와 같은 목소리가 쏟아졌다. 물론 법조계 내부에서도 예외는 아니었다. &#39;강간 문화&#39;를 간과하는 나의 법관 동료들에게라는 글이 시사인에 실리기도 했다. 이런 뉴스를 접하고 궁금증이 생겼다. n번방은 정말 판결문을 먹고 자란걸까? 법원의 성인지 감수성이 정말 심각한 수준인가? 혹시 몇몇 나쁜 사례가 언론을 통해 ‘과대표&#39;된 건 아닐까? 법원의 성인지 감수성은 정말 낮을까? . 궁금증을 풀기 위해 성폭력범죄 판결문을 직접 들여다봤습니다. 그리고 그 분석 결과를 ‘성인지 감수성 지수&#39;로 나타내보았다. . . 1. &#49324;&#50857; &#45936;&#51060;&#53552; . 판결문 데이터를 분석하려면 먼저 판결문이 있어야한다. 판결문 데이터는 전자법률도서관에서 수집했다. 사이트에서 ‘성폭력범죄&#39;를 검색해서, 검색 결과 잡히는 판결문 전체를 웹크롤링, json 파일로 저장했다. . 그 결과 1995년부터 2020년 6월 3일까지, 2400여개(총 2395개) 판결문을 확보했다. . . 이후 간단한 전처리를 거쳤다. . 2. &#50612;&#46500; &#44592;&#51456;&#51004;&#47196; &#39;&#49457;&#51064;&#51648; &#44048;&#49688;&#49457;&#39;&#51012; &#54217;&#44032;&#54624; &#44163;&#51064;&#44032;? . 위 세 가지 기준을 참고해 성인지 감수성이 낮은 판결문 8개를 선정, 기준으로 삼았다. . . . 3. &#54032;&#44208;&#47928;&#51032; &#39;&#49457;&#51064;&#51648; &#44048;&#49688;&#49457;&#39;&#51012; &#50612;&#46523;&#44172; &#51648;&#49688;&#54868;&#54624; &#44163;&#51064;&#44032;? . IF-IDF 알고리즘을 이용한다. . . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True). . import csv import pandas as pd import numpy as np import matplotlib.pyplot as plt import re data = pd.read_csv(&#39;/content/drive/Shareddrives/텍스트마이닝_씨스루조/data/final(noJudge).csv&#39;) data = data[[&#39;사건번호&#39;, &#39;법원명&#39;, &#39;날짜&#39;, &#39;죄명&#39;, &#39;주문&#39;, &#39;이유&#39;]] data.head(3) . 사건번호 법원명 날짜 죄명 주문 이유 . 0 2012고합543 2012전고31 | 울산지방법원 | 2013.6.14 | [&#39;[성폭력범죄의처벌및피해자보호등에관한법률위반(특수강도강간등)&#39;, &#39;성폭력범죄의처벌... | 주 문피고인을 징역 30년에 처한다.압수된 조립컴퓨터 본체(증 제5호) 중 피해자들... | 이 유범죄사실 및 부착명령 원인사실[범죄사실]1. 성폭력범죄의처벌및피해자보호등에관한... | . 1 2010고합63 2010전고2 | 대구지방법원 | 2010.3.26 | [&#39;[가.성폭력범죄의처벌및피해자보호등에관한법률위반(강간등상해)나.성폭력범죄의처벌및피... | [주문]피고인을 징역 10년에 처한다.피고인에 대한 공개정보를 10년간 정보통신망을... | [이유]▣ 범죄사실 및 부착명령 원인사실피고인 겸 피부착명령청구인(이하 ‘피고인’이... | . 2 2005헌마256 | 헌법재판소 | 2005.3.22 | [&#39;[성폭력범죄의처벌및피해자보호등에관한법률위헌확인]&#39;] | 주 문이 사건 심판청구를 각하한다. | 이 유1. 사건의 개요청구인은 성폭력범죄의처벌및피해자보호등에관한법률위반(강간등상해)... | . bad_cases = [&#39; 96도791&#39;, &#39;95도2914&#39;, &#39;2019누10176&#39;, &#39;2008고합220&#39;, &#39;2009고합6&#39;, &#39;2018노3606&#39;, &#39;2015노1180&#39;, &#39;2018노2855&#39;] . bad_list = list() for i, row in data.iterrows(): for number in bad_cases: if number in row[&#39;사건번호&#39;]: bad_list.append(row[&#39;이유&#39;]) # 판결문의 &#39;이유&#39; 부분에 판결 요지 등이 담겨 있으므로 이 부분을 분석한다. . bad_list . [&#34;이 유 1. 항소이유 요지 양형과중 (원심: 벌금 70만 원, 성폭력치료프로그램 이수 24시간, 몰수) 2. 직권판단 피고인의 항소이유에 대한 판단에 앞서 직권으로 본다. 가. 공소사실 피고인은 2018년경 같은 버스에 승차하고 있던 피해자가 하차를 위해 버스 단말기 앞에 서 있는 모습을 보고, 피고인의 휴대전화기의 카메라 촬영 기능을 이용하여 레깅스 바지를 입고 있는 피해자의 엉덩이 부위 등 하반신을 약 8초 동안 피해자 몰래 동영상 촬영하였다. 이로써 피고인은 성적 욕망 또는 수치심을 유발할 수 있는 피해자의 신체를 그 의사에 반하여 촬영하였다. 나. 이 사건 동영상이 &#39;성적 욕망 또는 수치심을 유발할 수 있는 타인의 신체&#39;를 촬영한 것에 해당하는지 여부 (소극) 1) &#39;카메라나 그 밖에 이와 유사한 기능을 갖춘 기계장치를 이용하여 성적 욕망 또는 수치심을 유발할 수 있는 다른 사람의 신체를 그 의사에 반하여 촬영&#39;하는 행위를 처벌하는 성폭력범죄의 처벌 등에 관한 특례법 제14조 제1항은 인격체인 피해자의 성적자유와 함부로 촬영당하지 아니할 자유를 보호하기 위한 것이다. 촬영한 부위가 &#39;성적욕망 또는 수치심을 유발할 수 있는 다른 사람의 신체&#39;에 해당하는지는 객관적으로 피해자와 같은 성별, 연령대의 일반적이고 평균적인 사람들의 관점에서 성적 욕망 또는 수치심을 유발할 수 있는 신체에 해당되는지를 고려함과 아울러, 피해자의 옷차림, 노출의 정도 등은 물론, 촬영자의 의도와 촬영에 이르게 된 경위, 촬영 장소와 촬영 각도 및 촬영 거리, 촬영된 원판의 이미지, 특정 신체 부위의 부각 여부 등을 종합적으로 고려하여 구체적ㆍ개별적ㆍ상대적으로 결정하여야 한다(대법원 2016. 1. 14. 선고 2015도16851 판결 참조). 2) 위 법리에 비추어 이 사건에 관하여 보건대, 기록에 의하여 인정되는 다음과 같은 사정들을 종합하여 보면, 피고인이 촬영한 피해자의 신체 부위가 성폭력범죄의 처벌 등에 관한 특례법 제14조 제1항 소정의 &#39;성적 욕망 또는 수치심을 유발할 수 있는 신체&#39;에 해당한다고 단정하기 어렵고, 결국 이 사건 공소사실이 합리적 의심의 여지가 없을 정도로 증명되었다고 할 수 없다. 그럼에도 원심이 이 사건 공소사실을 유죄로 인정한 것에는 성폭력범죄의 처벌 등에 관한 특례법 제14조 제1항 소정의 &#39;성적 욕망 또는 수치심을 유발할 수 있는 신체&#39;에 관한 법리 내지 사실을 오해하여 판결에 영향을 미친 위법이 있다고 할 것이다. ① 이 사건 동영상 촬영 당시 피해자는 엉덩이 바로 위까지 내려오는 다소 헐렁한 어두운 회색의 운동복 상의를 입고 있었고, 발목까지 내려오는 검정색 레깅스 하의에 운동화를 신고 있어 외부로 직접 노출되는 피해자의 신체 부위는 목 윗 부분과 손, 그리고 레깅스 끝단과 운동화 사이의 발목 부분이 전부였다. ② 이 사건 동영상 촬영 당시 피해자는 버스에서 하차하기 위하여 뒤쪽 출입문 옆에 서 있었고, 피고인은 위 출입문의 맞은편 좌석에서 피해자의 뒷모습을 촬영하였다. 피고인은 피해자의 상반신부터 발끝까지 전체적인 피해자의 우측 후방 모습을 촬영하였는데, 특별히 피해자의 엉덩이 부위를 확대하거나 부각시켜 촬영하지는 아니하였다. ③ 이 사건 동영상은 피고인이 버스에서 내리기 위해 서 있는 피해자의 뒤에서 피해자 몰래 촬영한 것이기는 하나, 피고인은 특별한 각도나 특수한 방법이 아닌 사람의 시야에 통상적으로 비춰지는 부분을 그대로 촬영하였다. ④ 피해자가 당시 입고 있던 레깅스는, 피해자와 비슷한 연령대의 여성들 사이에서 운동복을 넘어 일상복으로 활용되고 있고[한때 유행하였던 몸에 딱 붙는 청바지(이른바 &#39;스키니진&#39;)는 피해자가 입고 있던 레깅스와 소재의 색깔이나 질감에서 차이가 있는 것을 제외하고 신체에 밀착하여 몸매를 드러낸다는 점에서 별반 차이가 없다], 피해자 역시 위와 같은 옷차림으로 대중교통에 탑승하여 이동하였다. 따라서 레깅스를 입은 젊은 여성이라는 이유로 성적 욕망의 대상이라 할 수 없다. ⑤ 피해자는 경찰조사에서 당시 심정에 대하여 “기분 더럽고, 어떻게 저런 사람이 있나, 왜 사나 하는 생각을 했다.”고 진술하였다. 피고인의 이 사건 행위가 부적절하고 피해자에게 불쾌감을 유발하는 것임은 분명하다. 그러나 피해자의 위와 같은 진술이 불쾌감이나 불안감을 넘어 성적 수치심을 나타낸 것이라고 단정하기 어렵다. 그 후 피해자는 피고인에 대한 처벌불원의사를 표시하였다. ⑥ 한편, 피고인의 휴대전화는 압수되어 디지털분석 대상이 되었는데, 그 결과 추가로 입건된 영상은 없었다. 3. 결론 그렇다면, 원심판결에는 위와 같은 직권파기사유가 있으므로, 피고인의 양형부당 주장에 대한 판단을 생략한 채 형사소송법 제364조 제2항에 따라 원심판결을 파기하고, 변론을 거쳐 다시 다음과 같이 판결한다. [다시 쓰는 판결 이유] 이 사건 공소사실의 요지는 2.의 가.항 기재와 같은바, 이는 2.의 나.항에서 본 바와 같이 범죄의 증명이 없는 경우에 해당하므로 형사소송법 제325조 후단에 의하여 피고인에게 무죄를 선고하고, 무죄 판결의 요지를 형법 제58조 제2항에 따라 공시하기로 하여 주문과 같이 판결한다.&#34;, &#39;[이유]범죄사실피고인 변○○은 피해자 변○○(여, 16세)의 친조부, 피고인 변○○은 피해자의 백부, 피고인 변○○, 변○○는 각 피해자의 숙부이다.1. 피고인 변○○가. 피고인은 2001. 8.경 충북 ○○군 ○○면 ○○리 23에 있는 피고인의 집 방안에서, 피고인의 친손녀인 피해자(당시 9세)가 “할아버지, 이러지 마세요”라고 하는데도 강제로 피해자의 가슴과 음부를 만져, 친족관계에 있는 자로서 피해자를 강제로 추행하였다.나. 피고인은 2002. 7.경 위 피고인의 집 방안에서, 위와 같은 방법으로 친족관계에 있는 자로서 피해자(당시 10세)를 강제로 추행하였다.다. 피고인은 2005. 여름 일자불상 22:00경 위 피고인의 집 방안에서, 피해자(당시 13세)에게 “한 번 하자”고 하였다가 피해자로부터 거절당하자, “너는 큰아빠하고는 하면서 할아버지는 왜 못하게 하느냐”라고 말하고 강제로 옷을 벗기는 등으로 피해자로 하여금 반항하지 못하게 한 후 피해자를 1회 간음하여, 친족관계에 있는 자로서 피해자를 강간하였다.라. 피고인은 2006. 여름 일자불상 22:00경 위 피고인의 집 방안에서, 잠을 자고 있던 피해자(당시 14세)에게 달려들어 바지를 벗기고 몸 위로 올라가 반항하지 못하게 한 후 피해자를 1회 간음하여, 친족관계에 있는 자로서 피해자를 강간하였다.2. 피고인 변○○피고인은 2008. 5. 15. 06:00경 위 변○○과 함께 살고 있는 피고인의 집 방안에서, 부엌에서 설거지를 하고 있던 친조카인 피해자에게 “빨리 안방으로 들어가 성관계를 하자, 만약 성관계를 하지 않으면 가만두지 않겠다”라고 말하면서 피해자의 손목을 잡아끌어 강제로 방안으로 데리고 들어가 방바닥에 넘어뜨리는 등으로 피해자로 하여금 반항하지 못하게 한 후 바지와 팬티를 무릎까지 벗기고 피해자를 1회 간음하여, 친족관계에 있는 자로서 피해자를 강간하였다.3. 피고인 변○○피고인은 2005. 추석 전 무렵 일자불상 15:00경 충북 ○○군 ○○면 ○○리에 있는 산소 부근에서, 피고인이 벌초를 하는 동안 산소 옆에서 쉬고 있던 친조카인 피해자(당시 13세)의 팔을 붙들어 반항하지 못하게 한 후 강제로 바지와 팬티를 무릎까지 벗기고 “작은 아빠, 제발 이러지 마세요”라며 애원하는 피해자의 말을 무시하고 피해자를 1회 간음하여, 친족관계에 있는 자로서 피해자를 강간하였다.4. 피고인 변○○피고인은 2004. 11. 10.경 위 변○○의 집 방안에서, 자고 있던 친조카인 피해자(당시 12세)를 발견하고 욕정을 일으켜 피해자의 몸 위에 올라가 바지와 팬티를 내리고 손으로 피해자의 음부를 만져, 친족관계에 있는 자로서 피해자를 강제로 추행하였다.증거의 요지1. 피고인 변○○, 변○○의 법정진술 및 피고인 변○○의 일부 법정진술1. 증인 변○○의 법정진술1. 피고인 변○○, 변○○에 대한 각 검찰 피의자신문조서의 진술기재 및 피고인 변○○에 대한 검찰 피의자신문조서 중 일부 진술기재1. 변○○에 대한 검찰 진술조서1. 가족관계증명서, 제적등본법령의 적용1. 범죄사실에 대한 해당법조피고인 변○○ : 성폭력범죄의 처벌 및 피해자보호 등에 관한 법률 제7조 제1항,형법 제297조(각 친족관계에 의한 강간의 점), 성폭력범죄의 처벌 및 피해자보호 등에 관한 법률 제7조 제2항,형법 제298조(각 친족관계에 의한 강제추행의 점)피고인 변○○, 변○○ : 각 성폭력범죄의 처벌 및 피해자보호 등에 관한 법률 제7조 제1항,형법 제297조(친족관계에 의한 강간의 점)피고인 변○○ : 성폭력범죄의 처벌 및 피해자보호 등에 관한 법률 제7조 제2항,형법 제298조(친족관계에 의한 강제추행의 점)1. 경합범가중피고인 변○○ : 형법 제37조 전단, 제38조 제1항제2호, 제50조(형 및 범정이 가장 무거운 판시 제1. 라항의 죄에 대하여)1. 작량감경각 형법 제53조,제55조 제1항제3호(각 아래 양형의 이유에서와 같은 정상 참작)1. 미결구금일수의 산입피고인 변○○ : 형법 제57조1. 집행유예각 형법 제62조 제1항(각 아래 양형의 이유에서와 같은 정상 거듭 참작)피고인 변○○, 변○○의 각 주장에 대한 판단피고인 변○○은 자신의 손녀인 피해자가 귀엽다는 의미로 피해자의 가슴 등을 만진 일은 있지만 피해자를 강간하거나 강제로 추행한 사실은 없고, 피해자 변○○는 피해자를 강제추행한 사실이 없다는 취지의 주장을 한다.살피건대, 피해자가 수사기관 이래 이 법정에 이르기까지 이 사건 피해 내용 및 그 당시의 상황에 대하여 매우 구체적이고도 일관되게 진술하고 있고, 이 법정에서의 진술 태도 역시 매우 진지하며 피해 사실을 표현함에 있어서도 특별히 과장을 하고 있다고 보이지는 않는 점, 피해자가 자신의 친할아버지 또는 숙부인 위 피고인들에 대하여 허위의 진술을 하여 악의적으로 무고할만한 별다른 사정도 보이지 않는다는 점, 비록 피해자가 이 사건 각 피해 일시를 정확히 특정하지 못하고 있기는 하나, 이는 피해자의 낮은 지적능력과 장기간에 걸친 여러 건의 성폭력 피해로 인한 혼동에 기인한 것일 뿐이므로 이를 가지고 피해자 진술의 신빙성을 배척할 사정으로 삼기는 어렵다는 점 등에 비추어 보면, 피해자의 위 각 진술은 충분히 그 신빙성을 인정할 수 있고, 이와 같이 신빙성 있는 피해자의 수사기관 및 이 법정에서의 각 진술에 위에서 본 나머지 증거들을 종합하면, 위 피고인들에 대한 이 사건 각 공소사실을 인정하기에 충분하다고 할 것이므로, 피고인들의 위 주장은 받아들이지 아니한다. 양형의 이유이 사건 각 범행은 피해자의 친할아버지, 백부 또는 숙부의 관계에 있는 피고인들이 정신지체 상태에 있는 나이 어린 피해자를 자신들의 성적 욕구 해소의 수단으로 삼아 번갈아가며 강간하거나 강제추행한 것으로서, 그 범행 내용 자체로 인륜에 반하는 것이고 사회적 비난가능성도 매우 크다. 또한 피해자는 다른 누구로부터의 도움도 받지 못한 채 위와 같은 피고인들의 성폭력 범행에 장기간 노출됨으로써 씻을 수 없는 커다란 정신적 충격을 받았을 것으로 보이고, 실제로 전문기관에서의 피해자에 대한 상담 결과에 의하더라도 피해자는 자신의 일차적인 지지집단이라고 할 수 있는 ‘가족’에 대하여 소속감이나 친밀감을 느끼기보다는 두려움과 적대적 감정의 대상으로 여기고 있음을 알 수 있다. 이러한 사정을 감안하면 피고인들에 대하여는 중한 형의 선고가 불가피하다고 할 것이다.그러나 한편 피고인들이 자신들의 어려운 경제적 형편에도 불구하고 정신지체 등으로 인하여 피해자를 양육하지 못하는 피해자의 부모를 대신하여 그나마 최근까지 피해자를 양육하여 왔고, 피해자의 정신장애 정도 등에 비추어 보면 앞으로도 피해자에게는 그 가족인 피고인들의 지속적인 관심과 도움이 필요할 것으로 보이는 점, 이 사건 범행 후 일부 가족 구성원이 자살을 하고, 피고인 변○○ 역시 자살을 기도하기도 하는 등으로 피고인들 및 그 가족들 역시 이 사건 각 범행에 대한 처벌 여하에 관계없이 앞으로도 계속하여 벗어나기 어려운 정신적 고통을 감내하여야 할 것으로 보이는 점, 피고인 변○○, 변○○이 자신들의 잘못을 깊이 반성하고 있다는 점, 피고인 변○○은 고령으로 인하여, 피고인 변○○은 간질 증상으로 인하여 각 수형생활을 감내하기는 어려운 상태에 있다는 점, 피고인 변○○, 변○○, 변○○의 각 범행은 이미 수년 전에 저질러진 것이고, 그 이후 최근까지 별다른 추가범행이 없었다는 점, 피고인 변○○, 변○○, 변○○에게는 별다른 형사처벌을 받은 전력이 없다는 점, 피고인 변○○의 범행정도가 다른 나머지 피고인들에 비하여 상대적으로 경미하다는 점 등 기록에 나타난 이 사건의 특수성 및 피고인들에 대한 유리한 정상을 감안하여, 주문과 같이 형을 선고하기로 한다.&#39;, &#39;이 유1.항소이유의 요지원심의 형은 너무 무거워서 부당하다.2.판단이 사건 범행은 피고인이 7세의 여자 아동.청소년인 피해자를 강제로 추행한 것으로 인하여 아직 정신적.육체적으로 성숙하지 못한 피해자가 상당한 충격을 받았을 것으로 보이는 점 피고인이 피해자 측으로부터 용서받지 못하고 있는 점은 피고인에게 불리한 정상이다.피고인이 현재 77세의 고령으로 건강상태가 좋지 않은 점, 1965년 및 1982년에 이종 범죄로 두 차례 형사처벌을 받은 것 외에는 피고인에게 다른 범죄 전력이 없는 점, 피고인이 당심에 이르러 이 사건 범행을 인정하면서 뉘우치고 있는 점, 피고인의 처는 심한 치매증상으로 요양원에 입원해 있는 상태인 점 등은 피고인에게 유리한 정상이다.그 밖에 피고인의 나이,성행, 가족관게, 범행의 동기, 수단과 결과, 범행 후의 정황 등 양형의 조건이 되는 여러 사정과 대법원 양형위원회의 양형기준 적용 결과 등을 모두 종합하면 원심이 선고한 형은 다소 무거워서 부당하다.3.결론피고인을 위한 검사의 항소는 이유 있으므로 형사소송법 제364조 제6항에 따라 원심판결을 파기하고 변론을 거쳐 다시 다음과 같이 판결한다.범죄사실 및 증거의 요지이 법원이 인정하는 범죄사실 및 증거의 요지는 원심판결서 해당 부분의 기재와 같으므로 형사소송법 제369조에 의하여 이를 인용한다.법령의 적용1.범죄사실에 대한 해당법조 및 형의 선택성폭력범죄의 처벌 등에 관한 특례법 제7조 제3항, 형법 제298조(징역형 선택)1.작량감경형법 제53조, 제55조 제1항 제3호1.집행유예형법 제62조 제1항1.수강명령아동.청소년의 성보호에 관한 법률 제21조 제2항 본문1.등록정보의 공개명령 및 고지명령의 면제아동.청소년의 성보호에 관한 법률 제49조 제1항 단서, 제50조 제1항 단서[기록상 인정되는 피고인의 연령,직업, 가정환경, 사회적 유대관계,전과 및 재범의 위험성(동종 범죄 전력이 없음), 피고인의 신상정보에 대한 공개명령 또는 고지명령으로 인하여 기대되는 이익 및 예방 효과와 그로 인한 불이익 및 부작용 등 제반 사정을 종합하면 피고인의 신상정보를 공개, 고지하여서는 아니 될 특별한 사정이 있다고 판단된다( 대법원 2012.2.23.선고 2011도16863 판결 참조)]양형의 이유앞서 항소이유에 관한 판단에서 살펴본 바와 같은 여러 정상과 이 사건 변론에 나타난 여러 양형 조건을 종합적으로 고려하여 주문과 같이 형을 정한다.&#39;, &#39; 【이 유】[범죄사실] 피고인과 피해자의 부친인 공소외인은 평소 절친한 관계로, 피고인이 기초생활 수급자인 공소외인에게 무료로 살 수 있는 집을 소개시켜주어, 피해자를 포함한 공소외인의 가족은 ○○시 ○○면 ○○리에 있는 현재의 주거지에 살게 되었다. 피고인은 위 집 앞에 컨테이너를 설치하고 주로 그곳에 거주하면서 평소 피해자의 집에 자주 드나들었다. 1. 피고인은 2009. 4. 10. 15:00경 군산시 회현면에 있는 회현저수지 부근의 도로에서 (차량번호 생략) 리베로 화물차를 운행하여 가던 중, 피해자가 교복을 입고 걸어가는 것을 보고 피해자를 위 화물차 조수석에 태운 후, 피해자의 치마 속으로 오른손을 넣고 다리를 만져 피해자를 강제로 추행하였다. 2. 피고인은 2009. 4. 16. 16:30경 위 피해자의 집에서 피해자가 혼자 마당에 놀고 있는 것을 발견하고 피해자에게 9,000원을 주고 집 안으로 들어갔다. 피해자가 피고인을 따라 집 안으로 들어와 안방으로 가자, 피고인도 피해자를 따라 안방으로 들어갔다. 피고인은 피해자가 안방에 앉아 있는 것을 보고 피해자에게 입을 맞추려 하면서 음부에 손가락을 집어넣었다. 이에 피해자가 하지 말라고 말하면서 피해자의 방으로 들어가 문을 잠그자, 피고인의 피해자의 방 앞에서 10,000원을 주겠다고 하면서 문을 열라고 하였다. 피고인은 피해자가 문을 열어주자 피해자의 방으로 들어가, 피해자에게 방바닥에 앉으라고 하면서, 피해자의 어깨를 잡아 피해자가 반항하지 못하도록 한 후, 피해자의 옷 위로 가슴을 만지고 피해자의 음부에 손가락을 집어넣어 피해자를 강제로 추행하였다.[증거의 요지] 1. 피고인의 법정진술1. 피해자, 공소외인에 대한 각 검찰 진술조서 1. 피해자의 진술서 1. 각 수사보고(수사기록 제46-47쪽, 제49-51쪽)1. 장애인 증명서 사본 첨부보고1. 각 상담일지, 개별상담기록지[법령의 적용] 1. 범죄사실에 대한 해당법조 및 형의 선택각 성폭력범죄의 처벌 및 피해자보호 등에 관한 법률 제8조의2 제3항,형법 제298조(각 징역형 선택) 1. 경합범가중형법 제37조 전단,제38조 제1항제2호, 제50조[범정이 더 무거운&#39;, &#39;이 유 범 죄 사 실 피고인 겸 피부착명령청구인(이하 ‘피고인’이라 한다)은 1983. 8. 9. 서울지방법원 북부지원에서 강간치상죄로 징역 3년을 선고받은 전력이 있는 자로서, 술에 취하여 사물을 변별하거나 의사를 결정할 능력이 미약한 상태에서, 2008. 12. 11. 08:30경 안산시 단원구 .동 ..에 있는 .교회 앞 노상에서 근처 ‘.’초등학교로 등교하던 피해자 송.(여, 8세)을 발견하고 피해자를 강간하기로 마음먹고, 피해자에게 접근하여 교회에 다녀야 한다면서 피해자를 위 교회안 화장실로 끌고 갔다. 피고인은 그곳에서 바지를 벗고 피고인의 성기를 빨도록 하였으나 피해자가 이를 거부하자 주먹으로 피해자의 얼굴을 수회 때리고, 이에 피해자가 울자 시끄럽다면서 입으로 피해자의 볼을 깨물고, 피해자의 목을 졸라 기절하도록 하였다. 피고인은 계속해서 항거불능 상태에 빠진 피해자의 바지와 팬티를 벗기고 피고인의 성기를 삽입하여 강간하고, 이로 인하여 피해자에게 최소 8주 이상의 치료를 요하는 복부, 하배부 및 골반부위의 외상성 절단의 영구적 상해 및 비골골절상 등을 가하였고, 성폭력범죄를 다시 범할 위험성이 있다. 증거의 요지 1. 피고인의 일부 법정 진술(제3회 공판기일에서의 것)1. 박., 송., 조.에 대한 검찰 진술조서 1. 오.에 대한 경찰진술조서 1. 추송서(지문 및 혈흔 유전자 감정결과) 1. 압수조서 1. 관련사진(여러 사진 중 범인지목) 1. 상해진단서, 관련사진(피해자 상해부위 정도), 수사보고(진단서 편철) 1. 판시 전과 : 범죄경력조회, 수사보고(동종전과 판결문 첨부) 1. 판시 재범의 위험성 : 위 각 증거 및 판결전 조사보고서의 기재에 의하여 인정되는 피고인의 범행 당시의 행동, 범행의 방법 및 경위, 성폭력범죄의 범행전력, 정신상태, 성행 등에 비추어 재범의 위험성이 있다고 인정된다. 범죄의 성부에 대한 판단 살피건대, 앞서 적법하게 채택, 조사한 증거에 의하여 인정되는 다음과 같은 사정들, 즉 이 사건 범행현장에서 채취한 지문이 피고인의 것으로 밝혀진 사실, 이에 수사기관에서 피고인을 포함한 동종범죄 전력자 8명의 사진을 피해자에게 제시하면서 범인식별 절차를 취하였는데 피해자는 피고인을 명확히 지목한 사실, 피고인의 처 오.은 ‘피고인이 이 사건 범행 시각 이후인 2008. 12. 11. 09:00경 귀가하였으며, 그때 피고인이 사고를 쳤다고 자신에게 말한 적이 있다’고 진술한 사실, 피고인의 주거지에서 압수한 피고인의 운동화, 양말에서 혈흔이 발견되었으며, 그 혈흔은 피해자의 것으로 밝혀진 사실 등을 종합하여 보면, 이 사건 공소사실은 넉넉히 인정된다. 법령의 적용 1. 범죄사실에 대한 해당법조 및 형의 선택형법 제301조,제297조(무기징역형 선택) 1. 심신미약감경 형법 제10조 제2항,제55조 제1항제3호 1. 미결구금일수의 산입 형법 제57조 1. 열람명령 청소년의 성보호에 관한 법률 제37조 제1항제1호 1. 전자장치 부착명령 특정 성폭력범죄자에 대한 위치추적 전자장치 부착에 관한 법률 제9조 제1항,제5조 제1항제4호 1. 배상신청각하 소송촉진 등에 관한 특례법 제32조 제1항, 제2항,제25조 제1항, 제2항, 제3항제4호(이 사건 강간상해죄는 같은 법 제25조 제1항에서 규정하고 있는 배상명령을 명할 수 있는 범죄가 아니고, 같은 법 제25조 제2항의 규정에 따라 손해배상금에 대하여 합의된 바도 없을 뿐만 아니라, 변론종결시 까지만 신청할 수 있는데 그 기한을 도과하였고, 청구금액에는 배상명령신청의 대상이 아닌 일실수입 부분이 포함되어 있어 형사소송절차에서 배상명령을 함이 상당하지 아니하다고 인정되므로, 이 사건 배상신청은 부적법하다.) 양형의 이유 이 사건 범행은 피고인이 자신의 부당한 성적 욕구를 충족시키기 위하여 등교 중이던 8세에 불과한 피해자를 인근 건물의 화장실로 끌고 가 목을 졸라 기절시킨 후 강간하였고, 그 과정에서 상해를 가한 것이다. 더욱이 이 사건 범행으로 인하여 피해자는 복부의 장기가 음부 밖으로 노출될 정도로 그 피해는 참혹하였고, 최소 8주 이상의 치료를 요하는 복부, 하배부 및 골반부위의 외상성 절단 등의 영구적 상해를 입었고, 즉시 수술적 처치 등이 이루어지지 않았다면 생명이 위험할 정도였다. 따라서, 이 사건 범행으로 인하여 피해자 및 피해자의 가족은 평생토록 지울 수 없는 참담하고도 심각한 고통과 정신적 상처를 입었으며, 특히 피해자는 음부와 항문이 심하게 훼손되어 그 기능을 상실함으로써 앞으로도 정서적.육체적 성장 과정에서 심한 고통을 받을 것이 분명하고, 평생 동안 장애인으로 살아가야 한다. 이와 같이 이 사건 범행의 죄질과 범정이 극히 중함에도, 피고인은 자신의 잘못을 뉘우치기는 커녕 그때 그때 여러 변명을 하면서 범행을 부인하고 있고, 피해자의 피해회복을 위해 어떤 조치도 취하지 않았으며, 현재 피해자의 가족은 피고인에 대한 엄벌을 탄원하고 있다. 또한, 피고인에 대한 판결전 조사보고서의 기재에 의하면, 피고인은 알콜중독 및 행동통제력 부족으로 범죄유발 가능성이 많고, 재범위험성이 비교적 높은 것으로 나타났다. 이와 같은 이 사건 범행의 수단 및 방법, 그 결과, 범행 후의 정황, 피고인의 범죄전력, 재범위험성, 연령, 성행, 가정환경 등 모든 양형조건을 종합하여 볼 때, 피고인으로 인한 추가 범죄의 발생을 막아 이 사회를 보호하고, 피고인의 악성을 교화.개선시키기 위하여는 피고인을 장기간 이 사회에서 격리시킬 필요가 있다고 할 것이므로, 피고인에 대하여 주문과 같이 형을 정한다.&#39;, &#39;이 유 1. 피고인의 국선변호인의 상고이유 제1점에 대하여원심이, 피고인이 사실상 부부관계에 있는 피해자 강숙□에 대하여 그 판시와 같은 경위로 상해를 가한 사실을 인정하고, 피고인의 이와 같은 행위에 대하여 폭력행위등처벌에관한법률 제2조 제2항, 제1항, 형법 제257조 제1항을 적용하여 처단하였음은 옳고, 거기에 소론과 같은 채증법칙 위배로 인한 사실오인이나 폭력행위등처벌에관한법률 제2조 제2항, 제1항에 관한 법리오해의 위법이 있다고 할 수 없다.논지는 이유가 없다.2. 피고인의 상고이유에 대하여가. 원심판결 이유에 의하면 원심은, &#34;피고인이 1994. 7. 하순 일자미상 12:00경 ○○시 ○○면 ○○리 하제부락 소재 피고인의 집 안방에서 피고인의 의붓딸인 피해자 김미영(만 15세)을 그 판시와 같이 강간하려다가 미수에 그치고, 1995. 2.초 일자미상 11:00경 위 같은 장소에서 그 판시와 같은 경위로 김미영을 강간하였다&#34;라는 이 사건 공소사실에 대하여 성폭력범죄의처벌및피해자보호등에관한법률(이하 성폭력법이라고 한다) 제12조, 제7조 제1항, 제4항, 형법 제297조 또는 성폭력법 제7조 제1항, 제4항, 형법 제297조를 적용하여 이를 모두 유죄로 인정한 제1심판결(제1심 판시 제3, 4죄)을 그대로 유지하였다.나. 그러나 성폭력법 제7조 제1항은 존속 등 연장의 친족이 형법 제297조의 죄를 범한 때에 적용되고, 같은 법률 제7조 제3항에 의하면 위 제1항의 친족의 범위는 4촌 이내의 혈족으로 제한되나, 한편 같은 법률 제7조 제4항은 위 제1항의 존속 또는 친족은 사실상의 관계에 의한 존속 또는 친족을 포함한다고 규정하고 있는바, 형벌법규는 그 규정 내용이 명확하여야 할 뿐만 아니라 그 해석에 있어서도 엄격함을 요하고 유추해석은 허용되지 않는 것이므로 위 법률 제7조 제4항에서 규정하는 사실상의 관계에 의한 존속이라 함은, 자연혈족의 관계에 있으나 법정 절차의 미이행으로 인하여 법률상의 존속으로 인정되지 못하는 자(예컨대, 인지 전의 혼인 외의 출생자의 생부) 또는 법정혈족관계를 맺고자 하는 의사의 합치 등 법률이 정하는 실질관계는 모두 갖추었으나 신고 등 법정절차의 미이행으로 인하여 법률상의 존속으로 인정되지 못하는 자(예컨대, 사실상의 양자의 양부)를 말하고, 위와 같은 관계가 없거나 법률상의 인척에 불과한 경우에는 그 생활관계, 당사자의 역할ㆍ의사 등이 존속관계와 유사한 외관을 가진다는 이유만으로 위의 사실상의 관계에 의한 존속에 포함된다고 할 수는 없다고 할 것이다.다.이 사건에 있어서 보건대, 기록에 의하면 피고인은 피해자 김미영과 아무런 혈연관계가 없고 단지 김미영의 어머니인 강숙□와 사실상 부부로서 동거하는 관계에 있을 뿐이므로, 피고인은 성폭력법 제7조에서 규정하는 존속에 해당하지 아니하고, 한편 피해자 김미영의 법정대리인으로서 친권자인 강숙□가 위 공소사실에 대한 고소를 제기하였다가 이 사건 공소제기 전에 고소를 취소하였으므로, 이 사건 성폭력법위반죄 부분은 공소제기의 절차가 법률의 규정에 위반하여 무효인 때에 해당하여 이 점에 대하여는 형사소송법 제327조 제2호에 따라 공소기각의 판결을 선고하여야 할 것이다.그런데도 원심은 이와 다른 전제에 서서 이 사건 성폭력법위반 공소사실을 모두 유죄로 인정한 제1심판결(제1심 판시 제3, 4죄)을 그대로 유지하였으니, 원심판결에는 성폭력법 제7조 소정의 &#39;사실상의 관계에 의한 존속 &#39;에 관한 법리를 오해하여 판결 결과에 영향을 미친 위법이 있다고 하지 아니할 수 없고, 이 점을 지적하는 상고논지는 이유가 있다.라. 그런데 원심이 인용한 제1심은 그 판시 제1죄와 제2죄 및 제3죄는 이미 판결이 확정된 그 판시 첫머리 각 죄와 형법 제37조 후단의 경합범 관계에 있어 이에 대하여 따로 형을 정하는 한편, 이와는 별도로 그 판시 제4죄는 그 판시 제5죄와 형법 제37조 전단의 경합범 관계에 있다 하여 위 제4, 5죄에 대하여 단일한 형을 선고하였으므로, 원심판결 중 제1심 판시 제1, 2죄를 제외한 나머지 부분은 모두 파기를 면할 수 없다.3. 그러므로 피고인의 변호인의 나머지 상고이유에 대한 판단을 생략한 채 원심판결이 유지한 제1심 판시 제3죄 및 제4, 5죄 부분을 모두 파기하고, 이 부분 사건을 다시 심리ㆍ판단하게 하기 위하여 원심법원에 환송하며, 피고인의 나머지 상고는 이를 기각하기로 관여 법관의 의견이 일치되어 주문과 같이 판결한다.&#39;, &#34;이유 1. 항소이유의 요지 원심의 형(징역 2년, 집행유예 3년)은 너무 가벼워 부당하다. 2. 판단 피고인이 범죄사실 을 모두 자백하고, 어린 시절 정서적ㆍ경제적으로 어려운 시간을 보냈고 성장과정에서도 충분한 보호와 양육을 받지 못하였던 점, 달리 형사처벌을 받은 전력은 없는 점, 이 사건 범행에 이용된 아동청소년이용음란물 중에는 피고인 운영의 H 사이트(이하 이 사건 사이트라고 한다)에 접속한 회원들이 업로드한 것도 상당수 포함되어 있는 점, 범죄수익 대부분이 몰수보전 또는 추징보전처분을 통해 환수될 것으로 보이는 점, 2019. 4. 17. 혼인신고서를 접수하여 부양할 가족이 생긴 점 등은 피고인에게 유리한 정상이다. 그러나 피고인은 처음부터 아동청소년이용음란물을 취급하는 것이 성인음란물보다 경제적으로 이득이 될 것으로 생각하고 이 사건 사이트를 사들였고, 2015. 7. 8.경 이 사건 사이트 운영을 시작하면서 동시에 미국 및 중국 등의 비트코인 거래소에 계좌를 개설하여 비트코인으로 이용대금을 받기 시작하였다. 이 사건 사이트는 &#39;토르 브라우저&#39;1) 토르 브라우저는 복수의 노드를 무작위로 경유해 데이터를 전송하기 때문에 다크 웹 내에서 발생하는 범죄는 발견 및 추적이 매우 어렵다. 이 사건도 피고인이 아동청소년이용음란물의 썸네일 파일을 피고인의 ip에서 곧바로 불러오도록 코딩함으로 인해 발각되었다. 피고인은 자신의 ip 노출을 알고있었고 회원들로부터 경고를 받은 적도 있지만 경제적 수익을 위하여 그대로 두었다고 진술하였다. 라는 특수한 프로그램을 이용해서만 접근할 수 있다. 이러한 사이트를 통상 &#39;다크 웹&#39;이라고 칭하는데, 이러한 &#39;다크 웹&#39;은 일반적인 브라우저를 통해서는 게시물이 검색되지도 않고, IP 추적도 어렵다. 피고인이 수사기관에 의하여 체포된 2018. 3. 4.까지 약 2년 8개월 동안 이 사건 사이트에 가입한 회원 수는 128만여 명이고, 압수된 하드디스크에 저장된 음란물의 용량이 피고인의 진술에 의하더라도 총 8TB(파일 약 170,000개 가량, 파일명 중복된 것은 제외)가량이다. 피고인이 이 사건 사이트를 양수할 당시 이미 존재하던 아동청소년이용음란물 및 직접 CO 등의 음란물사이트에서 내려받아 게시한 아동청소년이용음란물이 총 20GB에 이르고, 중복, 혹은 불량 파일을 제외하고 확인되어 이 사건 공소사실에 포함된 아동청소년이용음란물의 수량이 3,055개(약 268GB 분량), 다운로드 건수는 7,293회이다. 피고인은 이 사건 사이트에 아동청소년음란물을 게시하면서 성인음란물(adultporn)은 올리지 말 것을 공지하기도 하였다. 2017. 5. 18.부터 2018. 3. 5.까지 불과 10개월 동안 위 사이트에서 발생한 다운로드 건수는 36만 건(파일 73,722개)이 넘고, 피고인은 비트코인의 시세가 오르면 이용자들의 요청에 따라 이 사건 사이트의 이용대금을 조정하는 운영을 하기도 하였다. 피고인은 범행기간 동안 이 사건 사이트 운영을 통하여 4억 원 가량의 범죄수익을 취득하였는데, 이를 수사기관의 추적이 어려운 비트코인으로 수수하고 이를 국내외 다수의 거래소로 옮기거나 재투자하는 등으로 관리하였으며, 차량 구입이나 전세금 및 생활비 등으로 지출하였다(그 과정에서 피고인은 &#39;아청법&#39;을 검색하거나 여성가족부의 &#39;성범죄알림e&#39; 앱을 내려받는 등 이 사건 범행의 위법성을 잘 알고 있었다). 이 사건과 같이 장기간 큰 규모로 영리를 목적으로 아동청소년음란물을 판매ㆍ배포ㆍ전시하는 행위는 보호의 대상인 아동청소년에 대한 인식을 성적으로 왜곡시키고, 비정상적인 성적 가치관을 퍼뜨릴 뿐 아니라, 아동청소년음란물 제작자와 그 소비자를 연결하여 주는 매개 혹은 촉진의 역할을 함으로써 사회적으로 미치는 해악이 매우 크다. 이상과 같은 점을 고려하면 피고인에게 이익이 되는 사정들을 두루 감안하더라도 엄중한 책임을 물을 필요가 있다. 원심이 선고한 형은 너무 가벼워서 부당하다. 3. 결론 그렇다면, 검사의 항소는 이유 있으므로 형사소송법 제364조 제6항에 따라 원심판결 중 몰수, 추징부분을 제외한 나머지 부분을 파기하고 변론을 거쳐 다음과 같이 다시 판결한다. [다시 쓰는 판결 이유] 범죄사실 및 증거의 요지 이 법원이 인정하는 범죄사실 및 그에 대한 증거의 요지는 원심판결 각 해당란 기재와 같으므로, 형사소송법 제369조에 따라 이를 그대로 인용한다. 법령의 적용 1. 범죄사실에 대한 해당법조 아동ㆍ청소년의성보호에관한법률 제11조 제2항(영리목적 아동ㆍ청소년이용음란물 판매ㆍ배포ㆍ제공ㆍ공연전시의 점, 포괄하여), 정보통신망이용촉진및정보보호등에관한법률 제74조 제1항 제2호, 제44조의7 제1항 제1호(정보통신망 이용 음란영상 등 배포ㆍ판매ㆍ공연전시의 점, 포괄하여) 1. 상상적 경합 형법 제40조, 제50조[형이 더 무거운 아동ㆍ청소년의성보호에관한법률위반(음란물제작ㆍ배포등)죄에 정한 형으로 처벌] 1. 이수명령 아동ㆍ청소년의 성보호에 관한 법률 제21조 제2항 본문 1. 취업제한명령 아동ㆍ청소년의 성보호에 관한 법률 제56조 제1항, 부칙(제15352호, 2018. 1. 16.) 제3조 양형의 이유 앞서 항소이유에 대한 판단 부분에서 살핀 점에 더하여 피고인의 나이, 성행, 환경, 가족관계, 범행 경위 및 결과, 범행 후의 정황 등 변론에 나타난 제반 양형 조건들을 고려하여 주문과 같이 형을 정한다. 신상정보 등록 및 제출의무 판시 아동ㆍ청소년의성보호에관한법률위반(음란물제작ㆍ배포등)죄의 범죄사실에 대하여 유죄판결이 확정되는 경우 피고인은 성폭력범죄의 처벌 등에 관한 특례법 제42조 제1항에서 정한 신상정보 등록대상자에 해당하게 되므로, 같은 법 제43조에 따라 관할기관에 신상정보를 제출할 의무가 있다(다만, 위 죄는 &#39;아동ㆍ청소년 대상 성폭력범죄&#39;에 해당되지 않고, 아동ㆍ청소년의 성보호에 관한 법률 제49조 제1항 제3호에서 정한 범죄도 아니므로, 공개ㆍ고지명령의 대상이 아니다).&#34;, &#39;【이 유】범죄사실피고인은 2009. 5. 말경부터 2009. 7. 초경까지 사이에 서울 강남구 □□동 000-0000호 자신의 집에서 피해자 a(여, 12세)와 휴대폰을 이용한 영상통화를 하면서 자신의 성기를 촬영한 동영상을 실시간으로 피해자의 휴대전화로 전송하였다.이로써 피고인은 자기 또는 다른 사람의 성적 욕망을 유발하거나 만족시킬 목적으로 전화를 통하여 성적 수치심이나 혐오감을 일으키는 영상을 상대방에게 도달하게 하였다.법령의 적용1. 범죄사실에 대한 해당법조 및 형의 선택성폭력범죄의 처벌 및 피해자보호 등에 관한 법률(이하 ‘성폭법’이라고 한다)제14조(벌금형 선택)1. 노역장 유치형법 제70조,제69조 제2항변호인의 주장과 이에 대한 판단1. 주장가. 공소사실 불특정 주장이사건 통신매체이용음란행위에 관한 공소사실은, 피고인인 2009. 5. 말경부터 2009. 7. 초경까지 사이에 피해자에게 자신의 성기를 촬영한 동영상을 전송하였다는 것으로서 공소사실 기재 자체에 의하더라도 그 범위가 심히 방대하여 피고인의 방어권 행사를 곤란하게 하고 있다. 따라서 위 공소사실은 범행일시가 특정되지 않아 공소제기가 무효인 경우에 해당하므로 공소기가판결이 선고되어야 한다.나. 무죄 주장피고인이 피해자에게 자신의 성기를 촬영한 영상(이하 ‘이 사건 영상’이라고 한다)을 전송한 행위는 피고인과 피해자의 합의에 의한 것으로서 피해자의 승낙이 있는 경우에 해당하여 위법성이 조각되고, 만약 성폭법 제14조의 문언내용을 중시하여 피해자의 승낙이 있는 경우에도 이를 처벌하는 것으로 해석한다면, 이는 개인의 사생활 및 성적 자기결정권, 행복추구권을 침해하는 것이 되어 헌법에 위배될 여지가 있다.2. 판단가. 공소사실의 불특정 주장에 대한 판단형사소송법 제254조 제4항에서 범죄의 일시ㆍ장소와 방법을 명시하여 공소사실을 특정하도록 한 취지는 법원에 대하여 심판의 대상을 한정하고 피고인에게 방어의 범위를 특정하여 그 방어권 행사를 용이하게 하기 위한 데 있는 것이므로, 공소제기된 범죄의 성격에 비추어 그 공소의 원인이 된 사실을 다른 사실과 구별할 수 있을 정도로 그 일시, 장소, 방법, 목적 등을 적시하여 특정하면 족하고, 그 일부가 다소 불명확 하더라도 그와 함께 적시된 다른 사항들에 의하여 그 공소사실을 특정할 수 있고 그리하여 피고인의 방어권 행사에 지장이 없다면 공소제기의 효력에는 영향이 없는 것이다( 대법원 2004. 3. 26. 선고 2003도8077 판결 참조).위 법리에 비추어 이 사건 공소사실의 특정 여부에 관하여 살피건대, 피고인 및 변호인은 제2회 공판기일에서 2010. 3. 26.자로 변경된 이 사건 공소사실을 인정한다고 진술하였을 뿐만 아니라 이 사건 공소사실에 기재된 기간 동안 피고인이 적어도 1회 이상 이 사건 영상을 피해자에게 전송한 사실에 관하여는 피고인과 피해자 모두 이를 인정하고 있으므로, 이에 의하면 비록 위 범행일시의 기재가 다소 포괄적이라 하더라도 그것만으로 이 사건 공소사실이 피고인의 방어권 행사에 지장을 초래한다고 볼 수 없어 변호사의 위 주장은 이유 없다.나. 피해자의 승낙 주장에 대한 판단1) 형법 제24조의 규정형법 제24조는 “처분할 수 없는 자의 승낙에 의하여 그 법익을 훼손한 행위는 법률에 특별한 규정이 없는 한 벌하지 아니한다.”라고 규정하고 있는바, 위 규정에 의하여 어떠한 행위가 위법성이 조각되기 위해서는 ① 처분할 수 있는 자의 처분할 수 있는 법익에 대한 승낙일 것, ② 유효한 승낙이 있을 것, ③ 승낙에 의한 법익훼손행위가 있을 것, ④ 법률에 특별한 규정이 없을 것 등의 요건이 충족되어야 한다. 이하 피고인이 피해자에게 이 사건 영상을 전송한 행위가 형법 제24조의 요건을 충족하는지 여부에 관하여 본다.2) 통신매체이용음란죄의 보호법익성폭법 제14조는 “자기 또는 다른 사람의 욕망을 유발하거나 만족시킬 목적으로 전화ㆍ우편ㆍ컴퓨터 기타 통신매체를 통하여 성적 수치심이나 혐오감을 일으키는 말이나 음향, 글이나 도화, 영상 또는 물건을 상대방에게 도달하게 한 자”를 처벌하도록 하고 있다. 그런데 위 규정에는 성폭법 제14조의2 제1항과 달리 ‘그 의사에 반하여’라는 명시적인 규정이 없어, 만약 그와 같은 문언형식을 중시하여 통신매체이용음란죄가 형법 제243조 소정의 음화반포죄 등과 같이 건전한 성풍속 등 사회적 법익을 주로 보호하는 조항으로 해석한다면, 피해자의 동의나 승낙이 있다고 하더라도 피고인의 이 사건 행위에 위법성이 조각된다고 보기 어렵다. 따라서 변호인의 주장을 판단하기 위한 전제로 우선, 통신매체이용음란죄의 주된 보호법익이 개인적 법익인지 아니면 사회적 법익인지 살펴볼 필요가 있다.성폭법 제14조는 “전화, 컴퓨터를 이용한 음란행위 등 새로운 유형의 성폭력범죄가 빈발하여 기존의 법체계로는 적절히 대처하기 어려워지자 특히 여성과 미성년자를 성폭력 범죄의 위협으로부터 보호하고 건전한 사회질서를 확립하는 것”을 입법취지로 하여, 성폭법 제정당시부터 친고죄(성폭법 제15조)로 규정되어 피해자의 고소없이는 공소를 제기할 수 없도록 되어 있다.또한, 위 조항은 통신매체를 이용하여 성적 수치심이나 혐오감을 주는 영상 등을 ‘특정 상대방’에게 도달하게 하는 행위를 처벌대상으로 하는 것이어서 이른바 ‘불특정 다수인’에 대한 행위를 행위유형으로 삼지 않고 있으며, 나아가 위 조항이 건전한 성풍속 등 사회적 법익을 주로 보호하는 것으로 보아 피해자의 승낙이나 사전 동의가 있어도 위법성이 조각되지 않는 것이라고 해석하게 되면, 성적 가치관과 자기결정권을 가진 성인들(연인이나 부부, 친구) 사이에 자유로운 합의에 따라 공연성 없이 영상물 등을 주고받는 행위까지도 모두 위 조항에 의하여 처벌할 수 있게 되어 헌법상 보호되는 개인의 사생활, 행복추구권, 성적 자기결정권 등을 과도하게 침해할 여지가 있게 된다.위와 같이 성폭법 제14조의 입법취지, 문언의 내용, 헌법상의 다른 기본권과의 조화 등을 종합하면, 통신매체이용음란죄는 “성적 자기결정권, 특히 성적 수치심을 일으키는 영상 등을 개인의 의사에 반하여 접하지 않을 권리”라는 개인적 법익을 주로 보호하는 것이고, 건전한 사회질서의 확립ㆍ성풍속의 보호 등은 2차적인 보호법익에 불과하다고 해석함이 상당하다. 이에 의하면 성폭법 제14조는 개인적 법익을 보호하는 규정으로서 원칙적으로 형법 제24조 소정의 피해자의 승낙 규정이 적용된다고 할 것이다.3) 승낙능력 및 피해자의 유효한 승낙 유무성폭법 제14조가 규정하는 통신매체이용음란죄의 보호법익을 개인적 법익으로 보더라도, 이 사건 당시 12세 11개월에 불과한 피해자가 승낙능력을 가지고 유효하게 피고인의 행위를 승낙하였는지 여부에 관하여 본다.가) 승낙능력의 의미형법 제24조 소정의 피해자의 승낙이 유효하기 위해서는 승낙자에게 승낙능력이 있어야 하고, 여기서 ‘승낙능력’이라고 함은 해당 보호법익을 포기한다는 것의 의미와 승낙행위의 결과를 충분히 인식하고 이성적으로 판단할 수 있는 자연적 통찰능력과 판단능력을 의미한다. 따라서 승낙능력을 판단함에 있어서는 당해 피해자의 나이, 지능, 지적 수준, 발달 성숙도 및 사회적응력 등에 비추어 그 범죄의 의미, 피해를 당한 정황, 승낙이 가지는 의미ㆍ내용ㆍ효과 등을 이해하고 알아차릴 수 있는 능력의 유무 등을 세심하게 관찰하여야 하고, 더욱이 피해자의 승낙 유무에서 기본적으로 중요시되어야 할 것은 당해 승낙이 법익주체의 진지하고 자유로운 의사에 의한 것인지 여부이며, 만약 피해자에게 의사형성과정의 자율성을 인정하기 어려운 사정이 있을 경우에는 그 승낙의 유효성을 부정함이 상당하다.나) 이 사건에서 피해자가 승낙능력을 가지고 유효한 승낙을 하였는지 여부앞서 본 증거들에 의하면, 피해자와 피고인은 서로 2009. 5.경부터 하루에도 수십 통씩 음성 및 영상통화, 문자메시지로 서로 연락하는 한편, 영상통화를 하면서 자위하는 모습 등을 보여준 사실이 인정된다. 이에 의하면 피해자는 피고인의 이 사건 영상 전송행위에 대하여 외관상으로 일응 승낙하였던 것으로 보인다.그러나 피고인의 이 사건 범행 당시 피해자는 12세 11개월에 불과한 미성년자이었고, 형법이 13세 미만자에 대한 간음ㆍ추행행위에 대하여 법익주체의 동의 유무를 불문하고 처벌하는 규정을 둠으로써(제305조) 13세 미만자의 법익처분능력을 부인하고 있는 점, 승낙능력은 개별 구성요건이 보호하는 법익에 따라 구체적으로 달리 판단해야 하는데, 13세 미만의 자들 중 사춘기에 있는 미성년자는 성년자에 비해 그 가치판단이 성숙하지 못하고 감정적ㆍ정서적으로도 미숙한 상태에서 성적 호기심이 왕성한 시기에 놓여 있으므로, 그에게 어느 정도 의사능력이 있다고 하더라도 이를 건전한 성도덕과 성적 자기 정체성을 가진 성년자들의 승낙능력과 같이 단순 비교ㆍ평가하기 어려운 점 등의 사정을 고려하면, 이 사건 피해자가 승낙능력을 가지고 유효하게 피고인의 행위를 승낙하였는지 여부는 피해자의 연령과 제반 정황을 종합하여 신중하게 평가할 필요가 있다.(1) 인정사실앞서 본 증거들과 이 사건 변론에 나타난 변론 전체의 취지를 종합하면, 아래의 사실을 인정할 수 있다.(가) 이사건 범행 당시 피고인은 48세, 피해자는 12세 11개월로 두 사람은 2009. 4.경 인터넷 버디버디 채팅방에서 처음 알게 되어 이후 캠코더로 성기 부분을 찍어 보여 주는 등으로 화상채팅을 하다가, 휴대전화번호를 교환한 이후에는 영상통화를 하면서 성기나 가슴을 보여주었는데, 피고인이 먼저 피해자에게 그 모습을 보여달라고 요구하였다.(나) 이후 피고인이 피해자에게 계속 만날 것을 요구하였으나, 피해자는 이를 거부하던 중 계속되는 피고인의 문자메시지, 통화 등으로 인해 만남을 허락하여 2009. 5. 31.경 피해자의 집 앞에서 피고인을 처음 만나게 되었는데, 피고인은 처음 만난 날 피해자를 데리고 성인용품점에 가 자위기구를 사 주었다. 피고인이 피해자에게 자위기구를 사 준 것은 피해자가 영상통화를 하면서 자위할 때 손이 아프다고 하자 이게 더 편할 거라고 하면서 사준 것으로, 이후 피해자는 피고인의 요구에 따라 자위기구를 사용하여 자위하는 모습을 영상통화로 피고인에게 보여주기도 하였다.(다) 피고인은 피해자를 두 번째 만났을 때 피고인이 먼저 피해자의 가슴과 음부를 만지며 자신의 성기를 애무하여 달라는 요구를 하였고, 이후 만났을 때에는 피해자를 데리고 모텔로 가 성관계를 가지기도 하였다(다만, 이 당시 피해자가 만 13세가 된 상태이었다.).(2) 판단위와 같은 피고인과 피해자의 연령 차이, 피고인과 피해자가 알게 된 경위, 피해자가 화상채팅, 영상통화 등을 하는 과정에서 피고인의 적극적인 요구로 피해자의 음부와 가슴, 자위하는 모습을 전송하였고, 당시 피해자가 피고인에게 그러한 행동을 적극적으로 요구하지는 아니하였던 점, 피고인은 피해자를 처음 만난 날 영상통화 때 사용할 자위기구를 사 주며 집에 가서 해 보라고 하는 등 영상통화할 때의 자위행위를 독려하는 듯한 행동까지 한 점, 이 사건 이후 피고인과 피해자가 만나는 과정에서도 피고인이 성적인 행위를 주도하였으며 피해자가 적극적으로 요구하는 등의 사정은 엿보이지 아니하는 점 등을 고려하면, 비록 피고인과 피해자가 영상통화를 하는 도중에 피고인이 피해자에게 이 사건 영상을 피해자에게 전송하였다 하더라도, 당시 성적 정체성과 가치관이 제대로 형성되기에 너무 어린 피해자의 저적 수준, 나이, 발달 성숙도, 사회적응력 등에 비추어, 당시 피해자가 진지하고 자유로운 의사에 기하여 법익침해를 예상하고 피고인의 행위를 승낙하였다고 단정하기 어렵고, 나아가 기록상 피해자에게 의사형성과정의 자율성을 인정하기도 어렵다고 할 것이다.결국 피해자에게 유효한 승낙이 있음을 전제로 한 변호인의 주장은 받아들이지 아니한다.양형의 이유피고인이 자신의 성적 욕구를 충족시킬 의도로 통신매체를 이용하여 성적 가치관이 미숙한 13세 미만의 피해자를 범행대상으로 삼은 점은 어떠한 이유로도 용납하기 어렵다. 사회인으로서 자신의 행동이 어린 피해자에게 향후 인격적으로 어떠한 후유증을 남기게 될 것인지에 관한 깊은 성찰 없이 성적 쾌감의 대상으로 피해자를 이용한 피고인의 행위에 대하여 피고인에게는 마땅히 그에 상응한 책임을 물어야 하겠으나, 피고인에게 동종의 범죄전력이 없는 점, 피고인에 대한 이 사건 공소사실은 해당 기간 동안 1회의 통신매체이용음란행위인 점, 피고인이 자신의 잘못을 뉘우치고 깊이 반성하고 있는 점, 그 밖에 이 사건 변론에 나타난 제반 양형요소를 참작하여 피고인에게 주문과 같이 형을 정한다.무죄부분1. 공소사실의 요지이 사건 공소사실 중 미성년자의제강간미수의 점(이하 ‘이 부분 공소사실’이라고 한다)은, 피고인은 2009. 6. 하순경부터 2009. 7. 15.까지 사이 12:00경 수원시 팔달구 □□로에 있는 팔달산 노상 주차장에 주차된 피고인 소유의 □□□ 차량 안에서 인터넷 채팅으로 알게 된 피해자 a(여, 12세)의 가슴과 성기를 손으로 만지고, 피해자로 하여금 손과 입으로 피고인의 성기를 애무하게 한 다음 피해자의 바지와 팬티를 벗기고 피고인의 성기를 피해자의 성기에 문지르다가 피해자와 성고하려 하였으나, 주위에 지나가는 사람들이 많아 그 뜻을 이루지 못하고 미수에 그쳤다는 것이다.2. 피고인과 변호인의 주장피고인이 이 사건 공소사실과 같이 피해자를 만난 날짜는 피고인의 휴대폰 발신내역에서 나타난 바와 같이 2009. 7. 21.경으로 피해자가 13세가 된 이후이므로, 이부분 공소사실은 구성요건해당성이 없어 무죄이다.3. 판단가. 이 사건의 쟁점이 사건의 쟁점은 피해자가 만 13세가 되기 이전인 ‘2009. 6. 하순경부터 2009. 7. 15.까지 사이에’피고인이 피해자를 간음하려다 미수에 그쳤는지 여부인바, 위 공소사실에 부합하는 증거로는 피해자에 대한 제2회 경찰 진술조서의 기내내용(수사기록 제76쪽)이 있다.나. 판단1) 인정사실앞서 본 각 증거에 의하면 아래의 사실을 인정할 수 있다.가) 피해자는 1996. 7. 17. 생이다.나) 피해자는 2009. 8. 13. 경찰에서 처음 조사를 받을 당시 “피고인과는 100일 전쯤에 처음 알게 되었다. 다섯 번 정도 만났는데 정확한 날짜는 잘 기억이 안 나지만 생일 전에 처음 만나고, 생일 근처에 또 한 번 만난 것 같아. 두 번째 만났을 때 피고인이 낮 11시~12시에 집 앞으로 와서 피해자에게 전화를 하여 피해자가 내려가서 피고인 차를 타고 도청 뒤 팔달산에 갔다. 피고인이 차 안에서 피해자의 가슴과 음부를 만졌지만 아직 피해자가 너무 어린 것 같다고 하며 그만뒀다.”, “피고인을 만날 때마다 매번 낮이었고, 피고인이 피해자의 집 앞에 와서 전화를 하면 피해자가 내려가서 피고인을 만났으며 다섯 번째 만난 날짜는 2009. 8. 9.쯤이었던 거 같다.”는 취지로 진술하였다.다) 피해자의 위 진술을 토대로 경찰이 피고인의 휴대전화 발신내역(2009. 5. 1.부터 2009. 8. 12.까지 피해자 휴대전화로 발신된 내역)을 확인한 결과, 피고인이 낮 시간에 피해자의 거주지인 수원 권선구 □□동에 도착하여 피해자의 휴대전화로 전화를 건 날짜는 2009. 5. 31., 2009. 7. 21., 2009. 7. 25., 2009. 8. 9.이고 그 외 2009. 8. 1.에는 수원 팔달구 □□o동에서 발신한 것으로 되어 있다.라) 이후 피해자와 피해자의 어머니는 2차 경찰에서 조사를 받으면서(2009. 9. 4.), “피고인과 피해자가 첫 번째 만난 날이 2009. 5. 31.이고 그 이후로 2009. 7. 21., 2009. 8. 13, 2009. 8. 9. 각 만난 것은 맞다.”고 진술하면서도, “피고인과 피해자가 팔달산에 갔던 것은 2009. 7. 16. 이전이다. 피고인이 피해자의 방학식날인 2009. 7. 16. 피해자의 생일 선물로 피해자에게 10만 원을 줬고, 팔달산에 갔던 두 번째 만남은 그 이전으로 피해자의 생일 이전임이 확실하다. 그 날은 피고인과 피해자가 오전에 통화해서 집 앞에서 만나기로 하고 피해자가 집 앞에 나가 기다렸기 때문에 피고인이 집 앞에서 피해자에게 전화한 기록은 없을 수도 있다.”라고 진술하면서 피고인과 피해자가 만난 횟수는 총 여섯 번이라고 진술을 번복하였다.마) 그런데 피해자가 피고인과 만난 날짜가 맞다고 인정한 각 날짜의 낮 시간에 피고인이 피해자에게 전화를 걸 당시의 기지국 주소를 보면, 아래 표 기재와 같이 기지국을 통하여 피고인이 피해자를 만나러 갔다가 돌아오는 이동경로를 모두 확인할 수 있는바, 이 부분 공소사실의 2009. 6. 하순경부터 2009. 7. 15.까지 사이에는 피해자의 거주지 근처에서 피고인의 휴대전화가 발신된 내역이나 아래와 같이 이동내역이 전혀 발견되지 아니한다.2)판단가) 위 인정사실에서 보는 바와 같이, 피해자가 최초 경찰에서 진술할 당시에는 매번 피고인이 집 앞에 와서 피해자의 휴대전화로 전화를 하면 그 때 집 앞으로 내려와서 피고인을 만났다고 진술했음에도, 통신사실자료를 확인한 결과 피고인이 두 번째로 피해자의 주거지 인근에서 전화한 것이 피해자의 13세 생일 이후인 2009. 7. 21.로 나타나자, 피해자는 피해자의 어머니가 경찰 조사에 참여한 상태에서 종전 진술을 번복하였다.나) 이러한 진술 번복 경위, 앞서 본 바와 같은 피고인과 피해자의 관계, 2009. 5. 1.부터 2009. 8. 12.까지의 통화횟수, 피고인과 피해자가 만나는 날에 나타난 피고인의 이동경로, 이 부분 공소사실 범행일시인 2009. 6. 하순경부터 2009. 7. 15.까지 사이에는 그러한 기지국 이동경로가 전혀 나타나지 아니하고 피고인이 피해자 주거지 근처에서 피해자의 휴대전화로 발신한 내역도 없는 점, 피해자가 최초 경찰에서 진술할 때는 정확히 기억이 나지 않는다고 했다가 2회 진술 시 오히려 더욱 구체적으로 경위를 진술한 점 등에 비춰 보면, 피해자의 13번째 생일 이전에 이 부분 공소사실 범행이 있었다는 피해자의 경찰 2회 진술내용은 섣불리 믿기 어렵다.다) 형사재판에서 공소가 제기된 범죄사실은 검사가 입증하여야 하고, 법관은 합리적인 의심을 할 여지가 없을 정도로 공소사실이 진실한 것이라는 확신을 가지게 하는 증명력을 가진 증거를 가지고 유죄로 인정하여야 하므로, 그와 같은 증거가 없다면 설령 피고인에게 유죄의 의심이 간다고 하더라도 피고인의 이익으로 판단할 수 밖에 없다( 대법원 2005. 4. 15. 선고 2005도767 판결 등 참조).결국 이 부분 공소사실은 범죄의 증명이 없는 경우에 해당하므로 형사소송법 제325조 후단에 의하여 피고인에게 무죄를 선고한다.&#39;] . # 이를 위해서는 먼저 colab에 mecab을 설치해야 한다 %%bash apt-get update apt-get install g++ openjdk-8-jdk python-dev python3-dev pip3 install JPype1 pip3 install konlpy . Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 InRelease Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 InRelease Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64 Release Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64 Release Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease Reading package lists... Reading package lists... Building dependency tree... Reading state information... python-dev is already the newest version (2.7.15~rc1-1). g++ is already the newest version (4:7.4.0-1ubuntu2.3). python3-dev is already the newest version (3.6.7-1~18.04). openjdk-8-jdk is already the newest version (8u292-b10-0ubuntu1~18.04). 0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded. Requirement already satisfied: JPype1 in /usr/local/lib/python3.7/dist-packages (1.3.0) Requirement already satisfied: typing-extensions; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from JPype1) (3.7.4.3) Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2) Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4) Requirement already satisfied: JPype1&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0) Requirement already satisfied: lxml&gt;=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6) Requirement already satisfied: numpy&gt;=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5) Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0) Requirement already satisfied: tweepy&gt;=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0) Requirement already satisfied: typing-extensions; python_version &lt; &#34;3.8&#34; in /usr/local/lib/python3.7/dist-packages (from JPype1&gt;=0.7.0-&gt;konlpy) (3.7.4.3) Requirement already satisfied: requests[socks]&gt;=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (2.23.0) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (1.15.0) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy&gt;=3.7.0-&gt;konlpy) (1.3.0) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (1.24.3) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (2021.5.30) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (3.0.4) Requirement already satisfied: PySocks!=1.5.7,&gt;=1.5.6; extra == &#34;socks&#34; in /usr/local/lib/python3.7/dist-packages (from requests[socks]&gt;=2.11.1-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (1.7.1) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy&gt;=3.7.0-&gt;konlpy) (3.1.1) . %env JAVA_HOME &quot;/usr/lib/jvm/java-8-openjdk-amd64&quot; . env: JAVA_HOME=&#34;/usr/lib/jvm/java-8-openjdk-amd64&#34; . %%bash bash &lt;(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh) pip3 install /tmp/mecab-python-0.996 . mecab-ko is already installed mecab-ko-dic is already installed mecab-python is already installed Done. Processing /tmp/mecab-python-0.996 Building wheels for collected packages: mecab-python Building wheel for mecab-python (setup.py): started Building wheel for mecab-python (setup.py): finished with status &#39;done&#39; Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141815 sha256=a56485f12e7e53231647f675a18ddfabd12ed624970603ab6d2c8ea65ff84068 Stored in directory: /root/.cache/pip/wheels/99/75/a6/e9e73a1dbd73579383644942ef18a6d17ad728a3052a1147fb Successfully built mecab-python Installing collected packages: mecab-python Found existing installation: mecab-python 0.996-ko-0.9.2 Uninstalling mecab-python-0.996-ko-0.9.2: Successfully uninstalled mecab-python-0.996-ko-0.9.2 Successfully installed mecab-python-0.996-ko-0.9.2 . data.head(2) . 사건번호 법원명 날짜 죄명 주문 이유 . 0 2012고합543 2012전고31 | 울산지방법원 | 2013.6.14 | [&#39;[성폭력범죄의처벌및피해자보호등에관한법률위반(특수강도강간등)&#39;, &#39;성폭력범죄의처벌... | 주 문피고인을 징역 30년에 처한다.압수된 조립컴퓨터 본체(증 제5호) 중 피해자들... | 이 유범죄사실 및 부착명령 원인사실[범죄사실]1. 성폭력범죄의처벌및피해자보호등에관한... | . 1 2010고합63 2010전고2 | 대구지방법원 | 2010.3.26 | [&#39;[가.성폭력범죄의처벌및피해자보호등에관한법률위반(강간등상해)나.성폭력범죄의처벌및피... | [주문]피고인을 징역 10년에 처한다.피고인에 대한 공개정보를 10년간 정보통신망을... | [이유]▣ 범죄사실 및 부착명령 원인사실피고인 겸 피부착명령청구인(이하 ‘피고인’이... | . def pre_process(text): &#39;&#39;&#39; 문자열을 받아 형태소 분석을 한 후, 명사형과 동사형만 필터링한다. &#39;&#39;&#39; import konlpy from konlpy.tag import Kkma, Komoran, Hannanum, Okt from konlpy.utils import pprint from konlpy.tag import Mecab # 형태소 분석기로 Mecab 사용 sent_tag = list() # 형태소 태그를 담을 리스트 words = str() # 특정 형태소만 필터링한 단어들만 남길 문자열 mecab = Mecab() morph = mecab.pos(text) sent_tag.append(morph) for sent in sent_tag: for word, tag in sent: if tag in [&#39;NNP&#39;, &#39;NNG&#39;, &#39;VV&#39;]: # 명사형 및 동사형만 words += word words += &#39; &#39; return words . processed_bad_list = list() # 전처리를 마친 데이터가 담길 리스트 for case in bad_list: processed = pre_process(case) processed_bad_list.append(processed) processed_bad_list . [&#39;유 항소 이유 요지 양형 중 원심 벌금 성폭력 치료 프로그램 이수 몰수 직권 판단 피고인 항소 이유 판단 직권 공소사실 피고인 버스 승차 피해자 하차 버스 단말기 앞 모습 보 피고인 휴대 전화기 카메라 촬영 기능 이용 레깅스 바지 입 피해자 엉덩이 부위 하반신 동안 피해자 동영상 촬영 피고인 성적 욕망 수치심 유발 있 피해자 신체 의사 반하 촬영 사건 동영상 성적 욕망 수치심 유발 있 타인 신체 촬영 해당 여부 소극 카메라 밖 기능 기계 장치 이용 성적 욕망 수치심 유발 있 사람 신체 의사 반하 촬영 하 행위 처벌 성폭력 범죄 처벌 특례법 항 인격체 피해자 성적 자유 촬영 자유 보호 촬영 부위 성적 욕망 수치심 유발 있 사람 신체 해당 피해자 성별 연령 일반 평균 사람 관점 성적 욕망 수치심 유발 있 신체 해당 고려 피해자 옷차림 노출 정도 촬영 의도 촬영 이르 경위 촬영 장소 촬영 각도 촬영 거리 촬영 원판 이미지 특정 신체 부위 부각 여부 종합 고려 구체 결정 대법원 선고 판결 참조 위 법리 비추 사건 관하 기록 의하 인정 다음 사정 종합 피고인 촬영 피해자 신체 부위 성폭력 범죄 처벌 특례법 항 소정 성적 욕망 수치심 유발 있 신체 해당 단정 사건 공소 사실 합리 의심 여지 정도 증명 원심 사건 공소 사실 유죄 인정 성폭력 범죄 처벌 특례법 항 소정 성적 욕망 수치심 유발 있 신체 법리 내지 사실 오해 판결 영향 위법 있 사건 동영상 촬영 당시 피해자 엉덩이 위 내려오 회색 운동복 상의 입 발목 내려오 검정 색 레깅스 하의 운동화 신 외부 노출 피해자 신체 부위 목 부분 손 레깅스 끝단 운동 사이 발목 부분 전부 사건 동영상 촬영 당시 피해자 버스 하차 위하 뒤쪽 출입문 옆 피고인 위 출입문 맞은편 좌석 피해자 뒷모습 촬영 피고인 피해자 상반신 발끝 전체 피해자 우측 후방 모습 촬영 피해자 엉덩이 부위 확대 부각 촬영 사건 동영상 피고인 버스 내리 피해자 뒤 피해자 촬영 피고인 특별 각도 특수 방법 사람 시야 통상 부분 촬영 피해자 당시 입 레깅스 피해자 연령 여성 사이 운동복 넘 일상복 활용 한때 유행 몸 붙 청바지 스키니 진 피해자 입 레깅스 소재 색깔 질감 차이 제외 신체 밀착 몸매 점 차이 피해자 위 옷차림 대중교통 탑승 이동하 레깅스 입 여성 이유 성적 욕망 대상 피해자 경찰 조사 당시 심정 대하 기분 사람 사나 하 생각 진술 피고인 사건 행위 피해자 불쾌감 유발 피해자 위 진술 쾌감 불안감 넘 성적 수치심 단정 후 피해자 피고인 처벌 의사 표시 한편 피고인 휴대 전화 압수 디지털 분석 대상 되 결과 추가 입건 영상 결론 원심 판결 위 직권 파기 사유 피고인 양형 부당 주장 판단 생략 형사 소송법 항 원심 판결 파기 변론 다음 판결 쓰 판결 이유 사건 공소 사실 요지 항 기재 항 범죄 증명 경우 해당 형사 소송법 후단 의하 피고인 무죄 선고 무죄 판결 요지 형법 항 공시 하 주문 판결 &#39;, &#39;이유 범죄 사실 피고인 변 피해자 변 친조부 피고인 변 피해자 백부 피고인 변 변 피해자 숙부 피고인 변 피고인 충북 군 면 리 있 피고인 집 방 안 피고인 친손녀 피해자 당시 할아버지 이러 하 강제 피해자 가슴 음부 친족 관계 있 피해자 강제 추행 피고인 피고인 집 방 안 위 방법 친족 관계 있 피해자 당시 강제 추행 피고인 여름 일자 불상 피고인 집 방 안 피해자 당시 하 하 피해자 거절 아빠 하 할아버지 하 하 말 강제 옷 벗기 피해자 반항 후 피해자 간음 친족 관계 있 피해자 강간 피고인 여름 일자 불상 피고인 집 방 안 잠 자 피해자 당시 달려들 바지 벗기 몸 위 반항 후 피해자 간음 친족 관계 있 피해자 강간 피고인 변 피고인 변 살 피고인 집 방 안 부엌 설거지 하 친조카 피해자 안방 성 관계 하 만약 관계 하 가만두 말 피해자 손목 잡아끌 강제 방 안 데리 방바닥 넘어뜨리 피해자 반항 후 바지 팬티 무릎 벗기 피해자 간음 친족 관계 있 피해자 강간 피고인 변 피고인 추석 전 일자 불상 충북 군 면 리 있 산소 부근 피고인 벌초 하 동안 산소 옆 쉬 친조카 피해자 당시 팔 붙들 반항 후 강제 바지 팬티 무릎 벗기 아빠 이러 애원 피해자 말 무시 피해자 간음 친족 관계 있 피해자 강간 피고인 변 피고인 변 집 방 안 자 친조카 피해자 당시 발견 욕정 피해자 몸 위 바지 팬티 내리 손 피해자 음부 친족 관계 있 피해자 강제 추행 증거 요지 피고인 변 변 법 정진술 피고인 변 일부 법 정진술 증인 변 법 정진술 피고인 변 변 검찰 피의자 신문 조서 진술 기재 피고인 변 검찰 피의자 신문 조서 일부 진술 기재 변 검찰 진술조서 가족 관계 증명서 제적 법령 적용 범죄 사실 해당 법조 피고인 변 성폭력 범죄 처벌 피해자 보호 법률 항 형법 조 친족 관계 강간 점 성폭력 범죄 처벌 피해자 보호 법률 항 형법 조 친족 관계 강제 추행 점 피고인 변 변 성폭력 범죄 처벌 피해자 보호 법률 항 형법 조 친족 관계 강간 점 피고인 변 성폭력 범죄 처벌 피해자 보호 법률 항 형법 조 친족 관계 강제 추행 점 경합범 가중 피고인 변 형법 전단 항 조 형 범정 판시 항의 죄 대하 작량감경 형법 항 아래 양형 이유 정상 참작 미결 구금 일수 산입 피고인 변 형법 집행유예 형법 항 아래 양형 이유 정상 참작 피고인 변 변 주장 판단 피고인 변 자신 손녀 피해자 의미 피해자 가슴 일 피해자 강간 강제 추행 사실 피해자 변 피해자 강제 추행 사실 취지 주장 살피 피해자 수사 기관 법정 이르 사건 피해 내용 당시 상황 대하 구체 일관 진술 법정 진술 태도 피해 사실 표현 있 과장 하 보이 점 피해자 자신 친할아버지 숙부인 위 피고인 대하 허위 진술 하 악의 무고 사정 보이 점 피해자 사건 피해 일시 특정 피해자 지적 능력 장기간 성폭력 피해 혼동 기인 가지 피해자 진술 신빙 배척 사정 삼 점 비추 피해자 위 진술 신빙 인정 있 신빙 있 피해자 수사 기관 법정 진술 위 나머지 증거 종합 위 피고인 사건 공소 사실 인정 피고인 위 주장 받아들이 양형 이유 사건 범행 피해자 친할아버지 숙부 관계 있 피고인 정신 지체 상태 있 나이 피해자 자신 성적 욕구 해소 수단 삼 번갈 강간 강제 추행 범행 내용 자체 인륜 반하 사회 비난 가능 피해자 도움 받 위 피고인 성폭력 범행 장기간 노출 씻 정신 충격 받 보이 전문 기관 피해자 상담 결과 의하 피해자 자신 일차 지지 집단 있 가족 대하 소속감 친밀감 느끼 두려움 적대 감정 대상 여기 있 사정 감안 피고인 대하 형 선고 한편 피고인 자신 경제 형편 정신 지체 인하 피해자 양육 피해자 부모 대신 최근 피해자 양육 피해자 정신 장애 정도 비추 앞 피해자 가족 피고인 지속 관심 도움 필요 보이 점 사건 범행 후 일부 가족 구성원 자살 하 피고인 변 자살 기도 하 피고인 가족 사건 범행 처벌 여하 앞 계속 벗어나 정신 고통 감내 보이 점 피고인 변 변 자신 잘못 반성 점 피고인 변 고령 인하 피고인 변 간질 증상 인하 수형 생활 감내 상태 있 점 피고인 변 변 변 범행 수년 전 이후 최근 추가 범행 점 피고인 변 변 변 형사 처벌 받 전력 점 피고인 변 범행 정도 나머지 피고인 비하 상대 점 기록 사건 특수 피고인 유리 정상 감안 주문 형 선고 &#39;, &#39;유 항소 이유 요지 원심 형 부당 판단 사건 범행 피고인 여자 아동 청소년 피해자 강제 추행 인하 정신 육체 성숙 피해자 상당 충격 받 보이 점 피고인 피해자 용서 받 점 피고인 불리 정상 피고인 고령 건강 상태 점 이종 범죄 차례 형사 처벌 받 피고인 범죄 전력 점 피고인 당 이르 사건 범행 인정 뉘우치 점 피고인 처 치매증 요양원 입원 상태 점 피고인 유리 정상 밖 피고인 나이 성행 가족 관 범행 동기 수단 결과 범행 후 정황 양형 조건 되 사정 법원 양형 위원회 양형 기준 적용 결과 종합 원심 선고 형 부당 결론 피고인 검사 항소 이유 있 형사 소송법 항 원심 판결 파기 변론 다음 판결 범죄 사실 증거 요지 법원 인정 범죄 사실 증거 요지 원심 판결서 해당 부분 기재 형사 소송법 조 의하 인용 법령 적용 범죄 사실 해당 법조 형 선택 폭력범 죄 처벌 특례법 항 형법 조 징역형 선택 작량감경 형법 항 집행유예 형법 항 수강 명령 아동 청소년 성 보호 법률 항 본문 등록 정보 공개 명령 고지 명령 면제 아동 청소년 성 보호 법률 항 단서 항 단서 기록 인정 피고인 연령 직업 가정 환경 사회 유대 관계 전 재범 위험 동종 범죄 전력 피고인 신상 정보 공개 명령 고지 명령 인하 기대 이익 예방 효과 이익 부작용 제반 사정 종합 피고인 신상 정보 공개 고지 특별 사정 있 판단 대법원 선고 판결 참조 양형 이유 항소 이유 판단 정상 사건 변론 양형 조건 종합 고려 주문 형 &#39;, &#39;유 범죄 사실 피고인 피해자 부친 공소 외인 평소 관계 피고인 기초 생활 수급 공소 외인 무료 있 집 소개 피해자 포함 공소 외인 가족 시 면 리 있 현재 주거지 살 되 피고인 위 집 앞 컨테이너 설치 거주 평소 피해자 집 드나들 피고인 군산시 회현면 있 회현 저수지 부근 도로 차량 번호 생략 리베로 화물차 운행 피해자 교복 입 걸어가 보 피해자 위 화물차 조수석 후 피해자 치마 속 오른손 넣 다리 피해자 강제 추행 피고인 피해자 집 피해자 혼자 마당 놀 발견 피해자 주 집 안 피해자 피고인 집 안 안방 가 피고인 피해자 안방 피고인 피해자 안방 앉 보 피해자 입 맞추 하 음부 손가락 집어넣 피해자 하 말 피해자 방 문 잠그 피고인 피해자 방 앞 주 하 문 열 피고인 피해자 문 열 피해자 방 피해자 방바닥 앉 하 피해자 어깨 잡 피해자 반항 후 피해자 옷 위 가슴 만지 피해자 음부 손가락 집어넣 피해자 강제 추행 증거 요지 피고인 법 정진술 피해자 공소 외인 검찰 진술조서 피해자 진술서 수사 보고 수사 기록 장애 증명서 사본 첨부 보 상담 개별 상담기 록지 법령 적용 범죄 사실 해당 법조 형 선택 성폭력 범죄 처벌 피해자 보호 법률 조 항 형법 조 징역형 선택 경합범 가중 형법 전단 항 조 범정 &#39;, &#39;죄 피고인 부착 명령 청구인 이하 피고인 서울 지방 법원 북부 지원 강간 치상죄 징역 선고 받 전력 술 취하 사물 변별 의사 결정 능력 상태 안산시 단원구 동 있 교회 앞 노상 근처 초등 학교 등교 피해자 송 여 발견 피해자 강간 마음먹 피해자 접근 교회 피해자 위 교회 안 화장실 끌 피고인 바지 벗 피고인 성기 빨 피해자 거부 주먹 피해자 얼굴 수회 때리 피해자 울 입 피해자 볼 깨물 피해자 목 기절 피고인 계속 항거 불능 상태 피해자 바지 팬티 벗기 피고인 성기 삽입 강간 인하 피해자 최소 이상 치료 요하 복부 배부 골반 부위 외상 절단 영구 상 비골 골절상 가하 성폭력 범죄 위험 증거 요지 피고인 일부 법정 진술 공판 기일 박 송 조 검찰 진술조서 경찰 진술조서 추송 지문 혈흔 유전자 감정 결과 압수 조서 관련 사진 사진 범인 지목 진단서 관련 사진 피해자 부위 정도 수사 보고 진단서 편철 판시 범죄 경력 조회 수사 보고 동종 전 판결문 첨부 판시 재범 위험 증거 판결 전 조사 보고서 기재 의하 인정 피고인 범행 당시 행동 범행 방법 경위 성폭력 범죄 범행 전력 정신 상태 성행 비추 재범 위험 있 인정 범죄 성부 판단 살피 채택 조사 증거 의하 인정 다음 사정 사건 범행 현장 채취 지문 피고인 사실 수사 기관 피고인 포함 동종 범죄 전력 사진 피해자 제시 인식 절차 취하 피해자 피고인 지목 사실 피고인 처 피고인 사건 범행 시각 이후 귀가 그때 피고인 사고 자신 말 있 진술 사실 피고인 주거지 압수 피고인 운동 양말 혈흔 발견 혈흔 피해자 사실 종합 사건 공소 사실 인정 법령 적용 범죄 사실 해당 법조 형 선택 형법 조 무기 징역형 선택 심신 미약 감경 형법 항 항 미결 구금 일수 산입 형법 열람 명령 청소년 성 보호 법률 항 전자 장치 부착 명령 특정 성폭력 범죄자 위치 추적 전자 장치 부착 법률 항 항 배상 신청 각하 소송 촉진 특례법 항 항 항 항 항 사건 강간 상해죄 항 규정 배상 명령 있 범죄 항 규정 손해 배상금 대하 합의 변론 종결 신청 있 기한 도과 청구 금액 배상 명령 신청 대상 일실 수입 부분 포함 형사 소송 절차 배상 명령 상당 인정 사건 배상 신청 부적 법 양형 이유 사건 범행 피고인 자신 부당 성적 욕구 충족 위하 등교 피해자 인근 건물 화장실 끌 목 기절 후 강간 과정 상해 사건 범행 인하 피해자 복부 장기 음부 밖 노출 정도 피해 참혹 최소 이상 치료 요하 복부 배부 골반 부위 외상 절단 영구 상해 입 수술 처치 이루어지 생명 위험 정도 사건 범행 인하 피해자 피해자 가족 참담 고통 정신 상처 입 피해자 음부 항문 훼손 기능 상실 앞 정서 육체 성장 과정 고통 받 평생 동안 장애 살아가 사건 범행 죄질 범정 중 피고인 자신 잘못 뉘우치 그때 그때 변명 하 범행 부인 피해자 피해 회복 조치 취하 피해자 가족 피고인 엄벌 탄원 피고인 결전 조사 보고서 기재 의하 피고인 알콜 중독 행동 통제력 부족 범죄 유발 가능 재범 위험 비교 사건 범행 수단 방법 결과 범행 후 정황 피고인 범죄 전력 재범 위험 연령 성행 가정 환경 양형 조건 종합 때 피고인 추가 범죄 발생 막 사회 보호 피고인 악 교화 개선 위하 피고인 장기간 사회 격리 필요 피고인 대하 주문 형 &#39;, &#39;유 피고인 국선 변호인 상고 이유 대하 원심 피고인 부부 관계 있 피해자 강숙 대하 판시 경위 사실 인정 피고인 행위 대하 폭력 행위 처벌 법률 항 항 형법 항 적용 처단 소론 증 법칙 위배 사실 오인 폭력 행위 처벌 법률 항 항 법리 오해 위법 있 논지 이유 피고인 상고 이유 대하 원심 판결 이유 의하 원심 피고인 하순 일자 미상 시 면 리 하제 부락 소재 피고인 집 안방 피고인 의붓딸 피해자 김미영 판시 강간 미수 그치 일자 미상 장소 판시 경위 김미영 강간 사건 공소 사실 대하 성폭력 범죄 처벌 피해자 보호 법률 이하 성폭력 법 항 항 형법 성폭력 법 항 항 형법 조 적용 유죄 인정 심판 결 심 판시 죄 유지 성폭력 법 항 존속 연장 친족 형법 조 죄 때 적용 법률 항 의하 위 항 친족 범위 이내 혈족 제한 한편 법률 항 위 항 존속 친족 사실 관계 존속 친족 포함 규정 형벌 법규 규정 내용 해석 있 요하 유추 해석 허용 위 법률 항 규정 사실 관계 존속 자연 혈족 관계 있 법정 절차 미 이행 인하 법률 존속 인정 인지 전 혼인 출생 생부 법정 혈족 관계 맺 하 의사 합치 법률 정하 실질 관계 갖추 신고 법정 절차 미 이행 인하 법률 존속 인정 사실 양자 양부 말 위 관계 법률 인척 경우 생활 관계 당사자 역할 의사 존속 관계 유사 외관 이유 위 사실 관계 존속 포함 사건 있 기록 의하 피고인 피해자 김미영 혈연관계 김미영 어머니 강숙 사실 부부 동거 관계 있 피고인 성폭력 법 조 규정 존속 해당 한편 피해자 김미영 법정 대리인 친권자 강숙 위 공소 사실 고소 제기 사건 공소 제기 전 고소 취소 사건 성폭력 법위 반 죄 부분 공소 제기 절차 법률 규정 위반 무효 때 해당 점 대하 형사 소송법 공소 기각 판결 선고 원심 전제 서 사건 성폭력 법위 반 공소 사실 유죄 인정 심판 결 심 판시 죄 유지 원심 판결 성폭력 법 소정 사실 관계 존속 법리 오해 판결 결과 영향 위법 있 하 점 지적 상고 논지 이유 원심 인용 심 판시 죄 죄 죄 판결 확정 판시 첫머리 죄 형법 후단 경합범 관계 있 대하 형 정하 한편 별도 판시 죄 판시 죄 형법 전단 경합범 관계 있 하 위 죄 대하 단일 형 선고 원심 판결 심 판시 죄 제외 나머지 부분 파 피고인 변호인 나머지 상고 이유 판단 생략 원심 판결 유지 심 판시 죄 죄 부분 파기 부분 사건 심리 하 위하 원심 법원 환송 피고인 나머지 상고 기각 관여 법관 의견 일치 주문 판결 &#39;, &#39;이유 항소 이유 요지 원심 형 징역 집행유예 부당 판단 피고인 범죄 사실 자백 시절 정서 경제 시간 성장 과정 보호 양육 받 점 형사 처벌 받 전력 점 사건 범행 이용 아동 청소년 이용 음란물 피고인 운영 사이트 이하 사건 사이트 접속 회원 업로드 상당수 포함 점 범죄 수익 대부분 몰수 보전 추징 보전 처분 환수 보이 점 혼인 고서 접수 부양 가족 점 피고인 유리 정상 피고인 처음 아동 청소년 이용 음란물 취급 성인 음란물 경제 이득 생각 사건 사이트 사건 사이트 운영 시작 동시 미국 중국 비트코인 거래소 계좌 개설 비트코인 이용 대금 받 시작 사건 사이트 토르 브라우저 토르 브라우저 복수 노드 무작위 경유 데이터 전송 다크 웹 발생 범죄 발견 추적 사건 피고인 아동 청소년 이용 음란물 썸 파일 피고인 불러오 코딩 발각 피고인 자신 노출 알 회원 경고 받 경제 수익 위하 두 진술 특수 프로그램 이용 접근 있 사이트 통상 다크 웹 칭하 다크 웹 일반 브라우저 게시물 검색 추적 피고인 수사 기관 의하 체포 동안 사건 사이트 가입 회원 수 압수 하드 디스크 저장 음란물 용량 피고인 진술 의하 파일 파 중복 제외 피고인 사건 사이트 양수 당시 존재 아동 청소년 이용 음란물 음란물 사이트 받 게시 아동 청소년 이용 음란물 이르 중복 불량 파일 제외 확인 사건 공소 사실 포함 아동 청소년 이용 음란물 수량 분량 다운로드 건수 피고인 사건 사이트 아동 청소년 음란물 게시 성인 음란물 올리 공지 하 동안 위 사이트 발생 다운로드 건수 파일 넘 피고인 비트코인 시세 오르 이용자 요청 사건 사이트 이용 대금 조정 운영 하 하 피고인 범행 기간 동안 사건 사이트 운영 통하 가량 범죄 수익 취득 수사 기관 추적 비트코인 수수 국내외 다수 거래소 옮기 재투자 관리 차량 구입 전세금 생활비 지출 과정 피고인 청법 검색 여성 가족 부 성범죄 앱 받 사건 범행 위법성 알 사건 장기간 규모 영리 목적 아동 청소년 음란물 판매 행위 보호 대상 아동 청소년 인식 성적 왜곡 정상 성적 가치관 아동 청소년 음란물 제작자 소비자 연결 매개 촉진 역할 사회 미치 해악 이상 점 고려 피고인 이익 되 사정 감안 책임 물 필요 원심 선고 형 부당 결론 검사 항소 이유 있 형사 소송법 항 원심 판결 몰수 추징 부분 제외 나머지 부분 파기 변론 다음 판결 쓰 판결 이유 범죄 사실 증거 요지 법원 인정 범죄 사실 증거 요지 원심 판결 해당란 기재 형사 소송법 조 인용 법령 적용 범죄 사실 해당 법조 아동 항 영리 목적 아동 판매 점 포괄 정보 통신망 용촉 정보 보호 법률 항 조 항 정보 통신망 이용 음란 영상 배포 점 포괄 상상 경합 형법 조 형 아동 음란물 제작 죄 형 처벌 이수 명령 아동 청소년 성 보호 법률 항 본문 취업 명령 아동 청소년 성 보호 법률 항 부칙 양형 이유 항소 이유 판단 부분 점 하 피고인 나이 성행 환경 가족 관계 범행 경위 결과 범행 후 정황 변론 제반 양형 조건 고려 주문 형 신상 정보 등록 제출 판시 아동 음란물 제작 죄 범죄 사실 대하 유죄 판결 확정 경우 피고인 성폭력 범죄 처벌 특례법 항 신상 정보 등록 대상자 해당 되 조 관할 기관 신상 정보 제출 의무 위 죄 아동 대상 성폭력 범죄 해당 아동 청소년 성 보호 법률 항 범죄 공개 대상 &#39;, &#39;유 범죄 사실 피고인 말경 초경 사이 서울 강남구 자신 집 피해자 여 휴대폰 이용 영상 통화 하 자신 성기 촬영 동영상 실시간 피해자 휴대 전화 전송 피고인 사람 성적 욕망 유발 만족 목적 전화 통하 성적 수치심 혐오감 일으키 영상 상대방 도달 법령 적용 범죄 사실 해당 법조 형 선택 폭력범 죄 처벌 피해자 보호 법률 이하 성 폭 법 조 벌금형 선택 노역장 유치 형법 항 변호인 주장 판단 주장 공소사실 특정 주장 사건 통신 매체 이용 음란 행위 공소사실 피고인 말경 초경 사이 피해자 자신 성기 촬영 동영상 전송 공소사실 기재 자체 의하 범위 피고인 방어 행사 곤란 하 위 공소 사실 범행 일시 특정 공소 제기 무효 경우 해당 공 소기 판결 선고 무죄 주장 피고인 피해자 자신 성기 촬영 영상 이하 사건 영상 전송 행위 피고인 피해자 합의 피해자 승낙 경우 해당 위법성 조각 만약 폭 법 조 문언 내용 중시 피해자 승낙 경우 처벌 해석 개인 사생활 성적 결정 행복 추구 침해 되 헌법 위배 판 공소사실 특정 주장 판단 형사 소송법 항 범죄 일시 방법 명시 공소 사실 특정 취지 법원 대하 심판 대상 한정 피고인 방어 범위 특정 방어 행사 하 있 공소 제기 범죄 성격 비추 공소 원인 사실 사실 구별 있 정도 장소 방법 목적 적시 특정 일부 불명확 하 적시 사항 의하 공소 사실 특정 있 하 피고인 방어 행사 지장 공소 제기 효력 영향 대법원 선고 판결 참조 위 법리 비추 사건 공소 사실 특정 여부 관하 살피 피고인 변호인 공판 기일 자 변경 사건 공소 사실 인정 진술 사건 공소 사실 기재 기간 동안 피고인 이상 사건 영상 피해자 전송 사실 관하 피고인 피해자 인정 의하 위 범행 일시 기재 포괄 하 사건 공소 사실 피고인 방어 행사 지장 초래 변호사 위 주장 이유 피해자 승낙 주장 판단 형법 조 규정 형법 조 처분 승낙 의하 법익 훼손 행위 법률 특별 규정 하 규정 위 규정 의하 행위 위법성 조각 처분 있 처분 있 법익 승낙 유효 승낙 있 승낙 법익 훼손 행위 있 법률 특별 규정 요건 충족 이하 피고인 피해자 사건 영상 전송 행위 형법 조 요건 충족 여부 관하 통신 매체 이용 음란죄 보호법 익성 폭 법 조 사람 욕망 유발 만족 목적 전화 기타 통신 매체 통하 성적 수치심 혐오감 일으키 말 음향 글 도화 영상 물건 상대방 도달 처벌 하 위 규정 성 폭 법 조 항 의사 반하 명시 규정 문언 형식 중시 통신 매체 이용 음란죄 형법 소정 음화 반포 죄 성풍 속 사회 법익 보호 조항 해석 피해자 동의 승낙 있 하 피고인 사건 행위 위법성 조각 변호인 주장 판단 전제 통신 매체 이용 음란죄 주 보호법익 개인 법익 사회 법익 필요 성 폭 법 조 전화 컴퓨터 이용 음란 행위 유형 성폭력 범죄 빈발 기존 법체계 대처 여성 미성년자 성폭력 범죄 위협 보호 사회 질서 확립 입법 취지 하 성 폭 법 제정 당시 친고죄 성 폭 법 조 규정 피해자 고소 공소 제기 되 위 조항 통신 매체 이용 성적 수치심 혐오감 주 영상 특정 상대방 도달 하 행위 처벌 대상 하 특정 다수 행위 행위 유형 삼 위 조항 성풍 속 사회 법익 보호 보 피해자 승낙 사전 동의 위법성 조각 해석 되 성적 가치관 결정 성인 연인 부부 친구 사이 자유 합의 영상물 주고받 행위 위 조항 의하 처벌 있 되 헌법 보호 개인 사생활 행복 추구 성적 자기결정권 과도 침해 위 성 폭 법 조 입법 취지 문언 내용 헌법 기본 조화 종합 통신 매체 이용 음란죄 성적 결정 성적 수치심 일으키 영상 개인 의사 반하 접하 권리 개인 법익 보호 사회 질서 확립 보호 보호법익 하 해석 상당 의하 성 폭 법 조 개인 법익 보호 규정 원칙 형법 소정 피해자 승낙 규정 적용 승낙 능력 피해자 유효 승낙 유무 폭 법 조 규정 통신 매체 이용 음란죄 보호법익 개인 법익 보 사건 당시 피해자 승낙 능력 가지 유효 피고인 행위 승낙 여부 관하 승낙 능력 의미 형법 소정 피해자 승낙 유효 승낙 승낙 능력 있 하 승낙 능력 해당 보호법익 포기 의미 승낙 행위 결과 인식 이성 판단 있 자연 통찰 능력 판단 능력 의미 승낙 능력 단함 있 피해자 나이 지능 지적 수준 발달 성숙도 사회 응력 비추 범죄 의미 피해 정황 승낙 가지 의미 이해 있 능력 유무 세심 관찰 하 피해자 승낙 유무 기본 중요 승낙 법익 주체 자유 의사 여부 만약 피해자 의사 형성 과정 자율 인정 사정 있 경우 승낙 유효 부정 상당 사건 피해자 승낙 능력 가지 유효 승낙 하 여부 증거 의하 피해자 피고인 하루 음성 영상 통화 문자 메시지 연락 한편 영상 통화 하 자위 모습 사실 인정 의하 피해자 피고인 사건 영상 전송 행위 대하 외관상 일 승낙 피고인 사건 범행 당시 피해자 미성년자 형법 미만 간음 대하 법익 주체 동의 유무 불문 처벌 규정 조 미만 법익 처분 능력 부인 점 승낙 능력 개별 구성요건 보호 법익 구체 판단 하 미만 자 사춘기 있 미성년자 성년자 가치 판단 성숙 감정 정서 상태 성적 호기심 시기 정도 의사 능력 있 하 성도덕 성적 정체 성년자 승낙 능력 단순 비교 점 사정 고려 사건 피해자 승낙 능력 가지 유효 피고인 행위 승낙 여부 피해자 연령 제반 정황 종합 신중 평가 필요 인정 증거 사건 변론 변론 전체 취지 종합 아래 사실 인정 있 이사건 범행 당시 피고인 피해자 사람 인터넷 버디 버디 채팅 방 알 되 이후 캠코더 성기 부분 찍 화상 채팅 하 휴대 전화 번호 교환 이후 영상 통화 하 성기 가슴 피고인 피해자 모습 요구 이후 피고인 피해자 요구 피해자 거부 계속 피고인 문자 메시지 통화 만남 허락 피해자 집 앞 피고인 만나 되 피고인 날 피해자 데리 성인 용품 점 자위기구 피고인 피해자 자위기구 피해자 영상 통화 하 자위 때 손 하 하 이후 피해자 피고인 요구 자위기구 사용 자위 모습 영상 통화 피고인 하 피고인 피해자 때 피고인 피해자 가슴 음부 만지 자신 성기 애무 요구 하 이후 때 피해자 데리 모텔 성 관계 가지 하 당시 피해자 상태 판 단위 피고인 피해자 연령 차이 피고인 피해자 알 경위 피해자 화상 채팅 영상 통화 하 과정 피고인 적극 요구 피해자 음부 가슴 자위 모습 전송 당시 피해자 피고인 행동 적극 요구 점 피고인 피해자 날 영상 통화 때 사용 자위기구 집 가 하 영상 통화 때 자위행위 독려 행동 사건 이후 피고인 피해자 만나 과정 피고인 성 행위 주도 피해자 적극 요구 사정 엿보이 점 고려 피고인 피해자 영상 통화 하 도중 피고인 피해자 사건 영상 피해자 전송 하 당시 성적 정체 가치관 형성 피해자 저적 수준 나이 발달 성숙도 사회 응력 비추 당시 피해자 자유 의사 기하 법익 침해 예상 피고인 행위 승낙 단정 기록 피해자 의사 형성 과정 자율 인정 피해자 유효 승낙 있 전제 변호인 주장 받아들이 양형 이유 피고인 자신 성적 욕구 충족 의도 통신 매체 이용 성적 가치관 미만 피해자 범행 대상 삼 점 이유 용납 사회인 자신 행동 피해자 향후 인격 후유증 남기 성찰 성적 쾌감 대상 피해자 이용 피고인 행위 대하 피고인 상응 책임 피고인 동종 범죄 전력 점 피고인 사건 공소 사실 해당 기간 동안 통신 매체 이용 음란 행위 점 피고인 자신 잘못 뉘우치 반성 점 밖 사건 변론 제반 양형 요소 참작 피고인 주문 형 무죄 부분 공소사실 요지 사건 공소 사실 미성년자 제강 미수 점 이하 부분 공소사실 피고인 하순 사이 수원시 팔달구 로 있 팔달산 노상 주차장 주차 피고인 소유 차량 안 인터넷 채팅 알 피해자 여 가슴 성기 손 만지 피해자 손 입 피고인 성기 애무 다음 피해자 바지 팬티 벗기 피고인 성기 피해자 성기 문지르 피해자 성고 주위 지나가 사람 뜻 이루 미수 피고인 변호인 주장 피고인 사건 공소 사실 피해자 날짜 피고인 휴대폰 발신 내역 피해자 이후 부분 공소 사실 구성요건 해당 무죄 판 사건 쟁점 사건 쟁점 피해자 되 이전 하순 사이 피고인 피해자 간음 미수 여부 위 공소 사실 부합 증거 피해자 경찰 진술조서 기내 내용 수사 기록 판단 인정 증거 의하 아래 사실 인정 있 피해자 피해자 경찰 처음 조사 받 당시 피고인 전 알 되 정도 정확 날짜 기억 나 생일 전 만나 생일 근처 때 피고인 집 앞 피해자 전화 하 피해자 내려가 피고인 차 타 도청 뒤 팔달산 피고인 차 안 피해자 가슴 음부 피해자 하 피고인 때 낮 피고인 피해자 집 앞 전화 하 피해자 내려가 피고인 날짜 취지 진술 피해자 위 진술 토대 경찰 피고인 휴대 전화 발신 내역 피해자 휴대 전화 발신 내역 확인 결과 피고인 낮 시간 피해자 거주지 수원 권선구 동 도착 피해자 휴대 전화 전화 날짜 수원 팔달구 동 발신 되 이후 피해자 피해자 어머니 경찰 조사 받 피고인 피해자 날 이후 맞 진술 피고인 피해자 팔달산 이전 피고인 피해자 방학 날 피해자 생일 선물 피해자 팔달산 만남 이전 피해자 생일 이전 날 피고인 피해자 오전 통화 집 앞 만나 하 피해자 집 앞 피고인 집 앞 피해자 전화 기록 진술 피고인 피해자 횟수 진술 번복 마 피해자 피고인 날짜 맞 인정 날짜 낮 시간 피고인 피해자 전화 당시 기지국 주소 보 아래 표 기재 기지국 통하 피고인 피해자 만나 돌아오 이동 경로 확인 있 부분 공소 사실 하순 사이 피해자 거주지 근처 피고인 휴대 전화 발신 내역 아래 이동 내역 발견 판 단가 위 인정 사실 보 피해자 최초 경찰 진술 당시 피고인 집 앞 피해자 휴대 전화 전화 하 때 집 앞 피고인 진술 통신 사실 자료 확인 결과 피고인 피해자 주거지 인근 전화 피해자 생일 이후 나타나 피해자 피해자 어머니 경찰 조사 참여 상태 종전 진술 번복 진술 번복 경위 피고인 피해자 관계 통화 횟수 피고인 피해자 만나 날 피고인 이동경 부분 공소사실 범행 일시 하순 사이 기지국 이동 경로 나타나 피고인 피해자 주거지 근처 피해자 휴대 전화 발신 내역 점 피해자 최초 경찰 진술 때 기억 나 진술 구체 경위 진술 점 피해자 생일 이전 부분 공소사실 범행 있 피해자 경찰 진술 내용 믿 형사재판 공소 제기 범죄 사실 검사 입증 하 법관 합리 의심 정도 공소사실 진실 확신 가지 하 증명력 증거 가지 유죄 인정 하 증거 피고인 유죄 의심 하 피고인 이익 판단 밖 대법원 선고 판결 참조 부분 공소 사실 범죄 증명 경우 해당 형사 소송법 후단 의하 피고인 무죄 선고 &#39;] . from sklearn.feature_extraction.text import TfidfVectorizer tfidf_vectorizer = TfidfVectorizer() # TF-IDF 객체 선언 tfidf_vectorizer.fit(processed_bad_list) # 단어를 학습시킴 bad_array = tfidf_vectorizer.transform(processed_bad_list).toarray() # TF-IDF를 이용해 단어 가중치가 적용된 숫자 벡터를 어레이 형태로 보자 bad_array . array([[0. , 0. , 0. , ..., 0. , 0.04970097, 0. ], [0.02002635, 0. , 0.02389556, ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0. , 0. , 0. ], ..., [0. , 0. , 0. , ..., 0. , 0. , 0. ], [0. , 0.02772433, 0. , ..., 0. , 0. , 0. ], [0. , 0. , 0. , ..., 0.01779676, 0.07118704, 0.0212352 ]]) . . def cos_sim(doc1, doc2): &#39;&#39;&#39; 코사인 유사도로 doc1과 doc2간 유사도를 구한다. &#39;&#39;&#39; from sklearn.metrics.pairwise import linear_kernel result = linear_kernel(doc1, doc2) return result def mean_sim(doc_list, target): &#39;&#39;&#39; 문서간 유사도 평균 구하기 &#39;&#39;&#39; temp = 0 n = 1 for doc in doc_list: temp += cos_sim(doc, target) n += 1 return temp/len(doc_list) . 4. &#49457;&#51064;&#51648; &#44048;&#49688;&#49457; &#51648;&#49688; &#49457;&#45733;&#51012; &#50612;&#46523;&#44172; &#54217;&#44032;&#54624; &#44163;&#51064;&#44032;? . . . . 그 결과 판결문 3개를 제외하고 나머지 7개 판결문은 비슷한 점수가 나왔다. 왼쪽은 문서간 유사도를 통해 산출한 성인지 감수성 점수이고 오른쪽은 연구자들이 직접 매긴 점수의 평균이다. . 꽤 잘 들어맞는다! . 5. Summary .",
            "url": "https://bibliophileryu.github.io/RyuHan/nlp/tf-idf/2021/07/07/_07_08_%EC%84%B1%EC%9D%B8%EC%A7%80%EA%B0%90%EC%88%98%EC%84%B1.html",
            "relUrl": "/nlp/tf-idf/2021/07/07/_07_08_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%8C%E1%85%B5%E1%84%80%E1%85%A1%E1%86%B7%E1%84%89%E1%85%AE%E1%84%89%E1%85%A5%E1%86%BC.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Let me begin my journey",
            "content": "print(&#39;Hi, I am RyuHan. Let us start a journey to the world.&#39;) .",
            "url": "https://bibliophileryu.github.io/RyuHan/blog/2021/07/07/_07_07_The_Show_Begins.html",
            "relUrl": "/blog/2021/07/07/_07_07_The_Show_Begins.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "TF-IDF를 이용한 문서간 유사도",
            "content": "&#51088;&#50672;&#50612;(&#53581;&#49828;&#53944;)&#47484; &#44228;&#49328; &#44032;&#45733;&#54620; &#50616;&#50612;&#47196; &#51064;&#53076;&#46377;&#54616;&#44592; . 자연어처리(NLP)를 위해서는 텍스트 데이터를 계산 가능한 언어로 바꿔야 한다. 즉, 숫자 벡터로 바꿔, 문서를 벡터 공간에 표현할 수 있다. . 텍스트 데이터를 숫자 벡터로 바꾸는 &#39;인코딩&#39;에는 여러 가지 방법이 있다. . 가장 간단한 방법이 문서 집합에서 단어 토큰을 생성하고 각 단어의 수를 세어 BOW(Bag of Words) 인코딩 벡터를 만드는 것이다. 사이킷런의 CountVectorizer 클래스를 사용하면 쉽게 할 수 있다. . 이 방법에서 한 단계 나아간 방법이 TF-IDF를 이용해 단어 가중치까지 반영하는 방법이 있다. . TF-IDF는 Term Frequency - Inverse Document Frequency)로, . 단어 가중치 기법 중 가장 일반적으로 알려진 알고리즘이다. | 특정 문서 내에서 단어 빈도가 높을수록, 전체 문서들에는 그 단어를 포함한 문서가 적을수록 TF-IDF 값이 높아진다. | 이 값을 이용해 모든 문서에 나타나는 흔한 단어들을 걸러내며, 특정 단어가 가지는 중요도를 측정하는 데 사용된다. | . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . with open(&#39;/content/drive/MyDrive/data/test_text.txt&#39;, &#39;r&#39;) as f: corpus = f.read() . corpus . &#39;Let me add some English sentences too!&#39; . from sklearn.feature_extraction.text import TfidfVectorizer text = [&#39;토마스 만은 평의원이며 곡물 상인이었던 토마스 요한 하인리히 만과 율리아 다 실바 브룬스 부부 사이에서 두 번째 아들로 독일의 뤼베크에서 태어났다.&#39;, # Doc[0] &#39;어머니 율리아는 7살 때 독일로 망명한 부분적 독일계 브라질리안이다.&#39;, # Doc[1] &#39;토마스 만의 아버지가 1891년에 돌아가시면서 회사는 청산되었다.&#39;, # Doc[2] &#39;1893년 뮌헨으로 이주하여 보험 회사의 견습 사원이 되었다.&#39;, # Doc[3] &#39;이때 첫 작품 &lt;호의&gt;가 잡지에 실리면서 문단에 데뷔하였다.&#39;] # Doc[4] tfidf_vectorizer = TfidfVectorizer() # TF-IDF 객체 선언 . tfidf_vectorizer.fit(text) # 단어를 학습시킴 tfidf_vectorizer.vocabulary_ # 단어사전을 출력 . {&#39;1891년에&#39;: 0, &#39;1893년&#39;: 1, &#39;7살&#39;: 2, &#39;견습&#39;: 3, &#39;곡물&#39;: 4, &#39;데뷔하였다&#39;: 5, &#39;독일계&#39;: 6, &#39;독일로&#39;: 7, &#39;독일의&#39;: 8, &#39;돌아가시면서&#39;: 9, &#39;되었다&#39;: 10, &#39;뤼베크에서&#39;: 11, &#39;만과&#39;: 12, &#39;만은&#39;: 13, &#39;만의&#39;: 14, &#39;망명한&#39;: 15, &#39;문단에&#39;: 16, &#39;뮌헨으로&#39;: 17, &#39;번째&#39;: 18, &#39;보험&#39;: 19, &#39;부부&#39;: 20, &#39;부분적&#39;: 21, &#39;브라질리안이다&#39;: 22, &#39;브룬스&#39;: 23, &#39;사원이&#39;: 24, &#39;사이에서&#39;: 25, &#39;상인이었던&#39;: 26, &#39;실리면서&#39;: 27, &#39;실바&#39;: 28, &#39;아들로&#39;: 29, &#39;아버지가&#39;: 30, &#39;어머니&#39;: 31, &#39;요한&#39;: 32, &#39;율리아&#39;: 33, &#39;율리아는&#39;: 34, &#39;이때&#39;: 35, &#39;이주하여&#39;: 36, &#39;작품&#39;: 37, &#39;잡지에&#39;: 38, &#39;청산되었다&#39;: 39, &#39;태어났다&#39;: 40, &#39;토마스&#39;: 41, &#39;평의원이며&#39;: 42, &#39;하인리히&#39;: 43, &#39;호의&#39;: 44, &#39;회사는&#39;: 45, &#39;회사의&#39;: 46} . sorted(tfidf_vectorizer.vocabulary_.items()) # 단어사전 정렬 . [(&#39;1891년에&#39;, 0), (&#39;1893년&#39;, 1), (&#39;7살&#39;, 2), (&#39;견습&#39;, 3), (&#39;곡물&#39;, 4), (&#39;데뷔하였다&#39;, 5), (&#39;독일계&#39;, 6), (&#39;독일로&#39;, 7), (&#39;독일의&#39;, 8), (&#39;돌아가시면서&#39;, 9), (&#39;되었다&#39;, 10), (&#39;뤼베크에서&#39;, 11), (&#39;만과&#39;, 12), (&#39;만은&#39;, 13), (&#39;만의&#39;, 14), (&#39;망명한&#39;, 15), (&#39;문단에&#39;, 16), (&#39;뮌헨으로&#39;, 17), (&#39;번째&#39;, 18), (&#39;보험&#39;, 19), (&#39;부부&#39;, 20), (&#39;부분적&#39;, 21), (&#39;브라질리안이다&#39;, 22), (&#39;브룬스&#39;, 23), (&#39;사원이&#39;, 24), (&#39;사이에서&#39;, 25), (&#39;상인이었던&#39;, 26), (&#39;실리면서&#39;, 27), (&#39;실바&#39;, 28), (&#39;아들로&#39;, 29), (&#39;아버지가&#39;, 30), (&#39;어머니&#39;, 31), (&#39;요한&#39;, 32), (&#39;율리아&#39;, 33), (&#39;율리아는&#39;, 34), (&#39;이때&#39;, 35), (&#39;이주하여&#39;, 36), (&#39;작품&#39;, 37), (&#39;잡지에&#39;, 38), (&#39;청산되었다&#39;, 39), (&#39;태어났다&#39;, 40), (&#39;토마스&#39;, 41), (&#39;평의원이며&#39;, 42), (&#39;하인리히&#39;, 43), (&#39;호의&#39;, 44), (&#39;회사는&#39;, 45), (&#39;회사의&#39;, 46)] . tf_idf_array = tfidf_vectorizer.transform(text).toarray() # TF-IDF를 이용해 단어 가중치가 적용된 숫자 벡터를 어레이 형태로 보자 tf_idf_array . array([[0. , 0. , 0. , 0. , 0.22585586, 0. , 0. , 0. , 0.22585586, 0. , 0. , 0.22585586, 0.22585586, 0.22585586, 0. , 0. , 0. , 0. , 0.22585586, 0. , 0.22585586, 0. , 0. , 0.22585586, 0. , 0.22585586, 0.22585586, 0. , 0.22585586, 0.22585586, 0. , 0. , 0.22585586, 0.22585586, 0. , 0. , 0. , 0. , 0. , 0. , 0.22585586, 0.36443818, 0.22585586, 0.22585586, 0. , 0. , 0. ], [0. , 0. , 0.35355339, 0. , 0. , 0. , 0.35355339, 0.35355339, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.35355339, 0. , 0. , 0. , 0. , 0. , 0.35355339, 0.35355339, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.35355339, 0. , 0. , 0.35355339, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ], [0.38775666, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.38775666, 0. , 0. , 0. , 0. , 0.38775666, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.38775666, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.38775666, 0. , 0.31283963, 0. , 0. , 0. , 0.38775666, 0. ], [0. , 0.35355339, 0. , 0.35355339, 0. , 0. , 0. , 0. , 0. , 0. , 0.35355339, 0. , 0. , 0. , 0. , 0. , 0. , 0.35355339, 0. , 0.35355339, 0. , 0. , 0. , 0. , 0.35355339, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.35355339, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.35355339], [0. , 0. , 0. , 0. , 0. , 0.37796447, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.37796447, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.37796447, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.37796447, 0. , 0.37796447, 0.37796447, 0. , 0. , 0. , 0. , 0. , 0.37796447, 0. , 0. ]]) . TF-IDF 알고리즘을 이용해 숫자 벡터로 인코딩을 마친 위 데이터간 유사도를 살펴보자. . 이를 위해, 코사인 유사도를 구해보자 . from numpy import dot from numpy.linalg import norm import numpy as np def cos_sim(A, B): return dot(A, B)/(norm(A)*norm(B)) . doc1= tf_idf_array[0] doc2= tf_idf_array[1] doc3= tf_idf_array[2] doc4 = tf_idf_array[3] . print(cos_sim(doc1, doc2)) #문서1과 문서2의 코사인 유사도 print(cos_sim(doc1, doc3)) #문서1과 문서3의 코사인 유사도 print(cos_sim(doc2, doc3)) #문서2과 문서3의 코사인 유사도 print(cos_sim(doc3, doc4)) #문서3과 문서4의 코사인 유사도 . 0.0 0.11401070555406811 0.0 0.0 .",
            "url": "https://bibliophileryu.github.io/RyuHan/nlp/tf-idf/2021/07/07/_07_01_TF_IDF.html",
            "relUrl": "/nlp/tf-idf/2021/07/07/_07_01_TF_IDF.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Practice MarkDown",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://bibliophileryu.github.io/RyuHan/markdown/2021/07/07/MarkDown_text.html",
            "relUrl": "/markdown/2021/07/07/MarkDown_text.html",
            "date": " • Jul 7, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://bibliophileryu.github.io/RyuHan/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://bibliophileryu.github.io/RyuHan/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Who is Ryu Han . 좋아하는 건 책 . 완전 채식을 지향한다 . 기자로 일했고 . 데이터를 공부한다 . 지구에 . 무해한 사람이 되고 싶다 . About this blog . 데이터를 공부하는 블로그다 . 기술을 통해 사회와 사람을 탐구한다 .",
          "url": "https://bibliophileryu.github.io/RyuHan/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  

  
      ,"page4": {
          "title": "Sample",
          "content": "hellow world . hellow world | hellow world | hellow world | .",
          "url": "https://bibliophileryu.github.io/RyuHan/sample/",
          "relUrl": "/sample/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://bibliophileryu.github.io/RyuHan/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}